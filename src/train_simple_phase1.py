"""
ì´ˆê°„ë‹¨ Phase 1 í•™ìŠµ
- ë¡œë´‡ 1ê°œ
- ì¥ì• ë¬¼ 1ê°œ (ê³ ì • ìœ„ì¹˜)
- ëœë¤ ì‹œì‘ ìœ„ì¹˜ â†’ ëª©ì ì§€ ì´ë™
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rl.agent import DQNAgent
from rl.trainer import DQNTrainer
from rl.demonstrations_extended import get_extended_demonstrations
from system import WormRobotSystem

def create_system_fn(rl_agent=None):
    """ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ 1ê°œ ì‹œìŠ¤í…œ"""
    return WormRobotSystem(
        rl_agent=rl_agent, 
        num_robots=1,
        obstacles=[(0, 1)]  # ì¤‘ì•™ ê·¼ì²˜ì— ì¥ì• ë¬¼ 1ê°œ
    )

def main():
    print("\n" + "=" * 70)
    print("ğŸ¯ ì´ˆê°„ë‹¨ Phase 1 í•™ìŠµ")
    print("=" * 70)
    print("ëª©í‘œ: ë¡œë´‡ 1ê°œê°€ ì¥ì• ë¬¼ 1ê°œë¥¼ í”¼í•´ ëª©ì ì§€ì— ë„ë‹¬")
    print("  - ë¡œë´‡: 1ê°œ (ëœë¤ ì‹œì‘ ìœ„ì¹˜)")
    print("  - ì¥ì• ë¬¼: 1ê°œ (ê³ ì • ìœ„ì¹˜: (0, 1))")
    print("  - ëª©ì ì§€: ëœë¤ (ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ë³€ê²½)")
    print("=" * 70)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê°„ë‹¨í•œ ë¬¸ì œì— ìµœì í™”)
    STATE_DIM = 13
    ACTION_DIM = 4  # 3 â†’ 4 (STAY ì¶”ê°€)
    
    agent = DQNAgent(
        state_dim=STATE_DIM,
        action_dim=ACTION_DIM,
        learning_rate=0.001,      # ì ë‹¹í•œ í•™ìŠµë¥ 
        gamma=0.95,               # ë‹¨ê¸° ë³´ìƒ ì¤‘ì‹œ
        epsilon_start=1.0,
        epsilon_end=0.05,
        epsilon_decay=0.9997,     # ëŠë¦° ê°ì†Œ
        use_target_net=True,      # ì•ˆì •í™”!
        device="cpu"
    )
    
    print("\nğŸ“ DQN ì„¤ì •:")
    print(f"  Learning Rate: 0.001")
    print(f"  Gamma: 0.95")
    print(f"  Epsilon: 1.0 â†’ 0.05 (decay=0.9997)")
    print(f"  Target Network: í™œì„±í™”")
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = DQNTrainer(
        agent=agent,
        create_system_fn=create_system_fn,
        num_episodes=20000,       # ì¶©ë¶„í•œ ì—í”¼ì†Œë“œ
        termination_time=80,      # ì ë‹¹í•œ ì‹œê°„ ì œí•œ
        batch_size=128,           # í° ë°°ì¹˜ í¬ê¸°
        buffer_size=100000,       # ëŒ€ìš©ëŸ‰ ë²„í¼
        log_interval=100,         # 100 ì—í”¼ì†Œë“œë§ˆë‹¤ ë¡œê·¸
        save_interval=1000,       # 1000 ì—í”¼ì†Œë“œë§ˆë‹¤ ì €ì¥
        model_path="outputs/simple_phase1.pth",
        use_tensorboard=True
    )
    
    print("\nğŸ“Š í•™ìŠµ ì„¤ì •:")
    print(f"  ì—í”¼ì†Œë“œ: 20,000ê°œ")
    print(f"  Termination Time: 80 ìŠ¤í…")
    print(f"  Batch Size: 128")
    print(f"  Replay Buffer: 100,000")
    
    # Happy Path ëŒ€ëŸ‰ ì¶”ê°€
    print(f"\nğŸ“– Happy Path (ì„±ê³µ ê²½í—˜) ì¶”ê°€ ì¤‘...")
    demos = get_extended_demonstrations(num_robots=1, num_random=500)
    trainer.replay_buffer.add_demonstrations(demos)
    print(f"   âœ… Demo ë¹„ìœ¨: {trainer.replay_buffer.get_demo_ratio()*100:.1f}%")
    print(f"   âœ… ì´ {len(demos)}ê°œì˜ ì„±ê³µ ê²½í—˜ ì¶”ê°€!")
    
    # í•™ìŠµ ì‹œì‘
    print(f"\n" + "=" * 70)
    print("ğŸš€ í•™ìŠµ ì‹œì‘!")
    print("=" * 70)
    print("ğŸ’¡ TensorBoardë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§:")
    print("   tensorboard --logdir=runs")
    print("=" * 70 + "\n")
    
    try:
        stats = trainer.train()
        
        # í‰ê°€
        print(f"\n" + "=" * 70)
        print("ğŸ“Š ìµœì¢… í‰ê°€")
        print("=" * 70)
        eval_stats = trainer.evaluate(num_episodes=50)  # 50íšŒ í‰ê°€
        
        print(f"\n" + "=" * 70)
        print("âœ… í•™ìŠµ ì™„ë£Œ!")
        print("=" * 70)
        print(f"ìµœì¢… ìŠ¹ë¥ :   {eval_stats['win_rate']*100:.1f}%")
        print(f"í‰ê·  ë³´ìƒ:   {eval_stats['avg_reward']:.1f}")
        print(f"í‰ê·  ìŠ¤í…:   {eval_stats['avg_steps']:.1f}")
        print("=" * 70)
        
        # ê²°ê³¼ íŒì •
        if eval_stats['win_rate'] >= 0.3:  # 30% ì´ìƒ
            print("\nğŸ‰ ì„±ê³µ! Phase 1ì„ ì¶©ë¶„íˆ í•™ìŠµí–ˆìŠµë‹ˆë‹¤!")
            print("   ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif eval_stats['win_rate'] >= 0.1:  # 10% ì´ìƒ
            print("\nâš ï¸ ë¶€ë¶„ ì„±ê³µ. ë” í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("   ì—í”¼ì†Œë“œ ìˆ˜ë¥¼ ëŠ˜ë ¤ì„œ ì¬í•™ìŠµì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        else:
            print("\nâŒ í•™ìŠµ ì‹¤íŒ¨. ì„¤ì •ì„ ì¬ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.")
            print("   ë³´ìƒ í•¨ìˆ˜ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ í•™ìŠµ ì¤‘ë‹¨ë¨!")
        trainer._save_model()
        print("ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print(f"\nì €ì¥ëœ ëª¨ë¸: outputs/simple_phase1.pth")
    print(f"í‰ê°€ ëª…ë ¹ì–´: python3.11 evaluate.py --model outputs/simple_phase1.pth\n")

if __name__ == "__main__":
    main()


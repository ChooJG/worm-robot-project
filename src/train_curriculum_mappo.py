"""
MAPPO ê¸°ë°˜ Curriculum Learning
ë¡œë´‡ ìˆ˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ê³ , ì´í›„ ì¥ì• ë¬¼ ì¶”ê°€

Phase 0: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (í˜‘ë ¥ í•™ìŠµ ê¸°ì´ˆ)
Phase 1: ë¡œë´‡ 3ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (í˜‘ë ¥ ì‹¬í™”)
Phase 2: ë¡œë´‡ 4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ìµœì¢… í˜‘ë ¥)
Phase 3: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 1ê°œ
Phase 4: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 3ê°œ
Phase 5: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 1ê°œ
Phase 6: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 2ê°œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rl.mappo_agent import MAPPOAgent
from system import WormRobotSystem
from moving_obstacle import create_moving_obstacles
from config import STATUS_WIN, STATUS_FAIL, STATUS_RUNNING


class MAPPOCurriculumTrainer:
    """MAPPO ê¸°ë°˜ Curriculum Learning íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, agent, log_interval=50, rollout_steps=2048):
        """
        Args:
            agent: MAPPOAgent ì¸ìŠ¤í„´ìŠ¤
            log_interval: ë¡œê·¸ ì¶œë ¥ ê°„ê²© (ì—í”¼ì†Œë“œ)
            rollout_steps: í•™ìŠµ ì „ ìˆ˜ì§‘í•  ê²½í—˜ ìŠ¤í… ìˆ˜
        """
        self.agent = agent
        self.log_interval = log_interval
        self.rollout_steps = rollout_steps
    
    def train_phase(self, phase_name, num_robots, obstacles=None, moving_obstacles=None,
                    num_episodes=5000, termination_time=80, success_threshold=0.3,
                    model_path=None):
        """
        ë‹¨ì¼ Phase í•™ìŠµ
        
        Args:
            phase_name: Phase ì´ë¦„
            num_robots: ë¡œë´‡ ìˆ˜
            obstacles: ì •ì  ì¥ì• ë¬¼ ë¦¬ìŠ¤íŠ¸ (None or [(x, y), ...])
            moving_obstacles: ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ ë¦¬ìŠ¤íŠ¸
            num_episodes: í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜
            termination_time: ìµœëŒ€ ìŠ¤í…
            success_threshold: ëª©í‘œ ì„±ê³µë¥ 
            model_path: ì €ì¥í•  ëª¨ë¸ ê²½ë¡œ
        """
        print("\n" + "=" * 70)
        print(f"ğŸ“ {phase_name} í•™ìŠµ ì‹œì‘")
        print("=" * 70)
        print(f"ë¡œë´‡ ìˆ˜: {num_robots}ê°œ")
        print(f"ì •ì  ì¥ì• ë¬¼: {obstacles if obstacles else 'ì—†ìŒ'}")
        print(f"ì›€ì§ì´ëŠ” ì¥ì• ë¬¼: {len(moving_obstacles) if moving_obstacles else 0}ê°œ")
        print(f"ì—í”¼ì†Œë“œ: {num_episodes}")
        print(f"ëª©í‘œ ì„±ê³µë¥ : {success_threshold * 100:.0f}%")
        print("=" * 70)
        
        # ì‹œìŠ¤í…œ ìƒì„± í•¨ìˆ˜
        def create_system_fn():
            return WormRobotSystem(
                rl_agent=None,  # MAPPOëŠ” ì™¸ë¶€ì—ì„œ í–‰ë™ ì„ íƒ
                num_robots=num_robots,
                obstacles=obstacles,
                moving_obstacles=moving_obstacles
            )
        
        # ì¤‘ë‹¨ëœ í•™ìŠµ ì¬ê°œ í™•ì¸
        resumed = False
        if model_path:
            tmp_interrupted = model_path.replace('.pth', '_tmp_interrupted.pth')
            tmp_error = model_path.replace('.pth', '_tmp_error.pth')
            
            if os.path.exists(tmp_interrupted):
                print(f"\nğŸ”„ ì¤‘ë‹¨ëœ í•™ìŠµ ë°œê²¬! ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤...")
                print(f"   ëª¨ë¸ ë¡œë“œ: {tmp_interrupted}")
                self.agent.load(tmp_interrupted)
                resumed = True
            elif os.path.exists(tmp_error):
                print(f"\nğŸ”„ ì˜¤ë¥˜ë¡œ ì¤‘ë‹¨ëœ í•™ìŠµ ë°œê²¬! ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤...")
                print(f"   ëª¨ë¸ ë¡œë“œ: {tmp_error}")
                self.agent.load(tmp_error)
                resumed = True
        
        if resumed:
            print(f"   âœ… ì´ì „ í•™ìŠµ ìƒíƒœì—ì„œ ì¬ê°œí•©ë‹ˆë‹¤!")
        
        # í†µê³„
        stats = {
            "episode_rewards": [],
            "episode_steps": [],
            "episode_losses": [],
            "success_count": 0,
            "fail_count": 0
        }
        
        print(f"\nğŸš€ í•™ìŠµ ì‹œì‘!\n")
        
        best_success_rate = 0.0
        total_steps = 0
        
        # í•™ìŠµ ë£¨í”„
        try:
            for episode in range(num_episodes):
                episode_reward, episode_steps, status = self._run_episode(
                    create_system_fn, termination_time
                )
                
                total_steps += episode_steps
                
                # í†µê³„ ê¸°ë¡
                stats["episode_rewards"].append(episode_reward)
                stats["episode_steps"].append(episode_steps)
                
                if status == STATUS_WIN:
                    stats["success_count"] += 1
                elif status == STATUS_FAIL:
                    stats["fail_count"] += 1
                
                # ì¼ì • ìŠ¤í…ë§ˆë‹¤ í•™ìŠµ
                if total_steps >= self.rollout_steps:
                    actor_loss, critic_loss, entropy = self.agent.train()
                    stats["episode_losses"].append(actor_loss)
                    total_steps = 0
                
                # ë¡œê·¸ ì¶œë ¥
                if (episode + 1) % self.log_interval == 0:
                    recent = min(self.log_interval, len(stats["episode_rewards"]))
                    avg_reward = sum(stats["episode_rewards"][-recent:]) / recent
                    avg_steps = sum(stats["episode_steps"][-recent:]) / recent
                    avg_loss = sum(stats["episode_losses"][-recent:]) / recent if stats["episode_losses"] else 0
                    
                    # ìµœê·¼ ì„±ê³µë¥  ê³„ì‚°
                    recent_episodes = stats["success_count"] + stats["fail_count"]
                    recent_success_rate = stats["success_count"] / recent_episodes if recent_episodes > 0 else 0
                    
                    print(
                        f"Ep {episode + 1:5d}/{num_episodes} | "
                        f"Reward: {avg_reward:7.1f} | "
                        f"Steps: {avg_steps:4.1f} | "
                        f"Loss: {avg_loss:.4f} | "
                        f"Success: {recent_success_rate*100:4.1f}% | "
                        f"Win: {stats['success_count']:4d}"
                    )
                    
                    # ìµœê³  ì„±ê³µë¥  ê°±ì‹ 
                    if recent_success_rate > best_success_rate:
                        best_success_rate = recent_success_rate
                        if model_path:
                            self.agent.save(model_path)
                            print(f"   âœ… ìƒˆ ìµœê³  ì„±ê³µë¥ ! ëª¨ë¸ ì €ì¥: {model_path}")
                
                # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì²´í¬
                if episode > 1000 and episode % 500 == 0:
                    total_episodes = stats["success_count"] + stats["fail_count"]
                    current_success_rate = stats["success_count"] / total_episodes if total_episodes > 0 else 0
                    
                    if current_success_rate >= success_threshold:
                        print(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±! (ì „ì²´ ì„±ê³µë¥ : {current_success_rate*100:.1f}%)")
                        break
        
        except KeyboardInterrupt:
            print(f"\n\nâš ï¸ ì‚¬ìš©ìê°€ í•™ìŠµì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤!")
            if model_path:
                tmp_path = model_path.replace('.pth', '_tmp_interrupted.pth')
                self.agent.save(tmp_path)
                print(f"   ğŸ’¾ ì„ì‹œ ëª¨ë¸ ì €ì¥: {tmp_path}")
                print(f"   í˜„ì¬ê¹Œì§€ ì§„í–‰: {episode + 1}/{num_episodes} ì—í”¼ì†Œë“œ")
            raise
        
        except Exception as e:
            print(f"\n\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if model_path:
                tmp_path = model_path.replace('.pth', '_tmp_error.pth')
                self.agent.save(tmp_path)
                print(f"   ğŸ’¾ ì„ì‹œ ëª¨ë¸ ì €ì¥: {tmp_path}")
            raise
        
        # ìµœì¢… ì €ì¥
        if model_path:
            self.agent.save(model_path)
        
        # ìµœì¢… í†µê³„
        total_episodes = stats["success_count"] + stats["fail_count"]
        final_success_rate = stats["success_count"] / total_episodes if total_episodes > 0 else 0
        
        print("\n" + "=" * 70)
        print(f"âœ… {phase_name} ì™„ë£Œ!")
        print("=" * 70)
        print(f"ì´ ì„±ê³µ: {stats['success_count']}")
        print(f"ì´ ì‹¤íŒ¨: {stats['fail_count']}")
        print(f"ìµœì¢… ì„±ê³µë¥ : {final_success_rate * 100:.1f}%")
        print(f"ìµœê³  ì„±ê³µë¥ : {best_success_rate * 100:.1f}%")
        print("=" * 70)
        
        return stats, final_success_rate
    
    def _run_episode(self, create_system_fn, termination_time):
        """ì—í”¼ì†Œë“œ ì‹¤í–‰ (MAPPOìš©)"""
        system = create_system_fn()
        num_robots = len(system.robots)
        
        episode_reward = 0.0
        step_count = 0
        
        while not system.is_done() and step_count < termination_time:
            # í˜„ì¬ ìƒíƒœ
            current_states = {}
            for rid in range(num_robots):
                if rid in system.environment.state.robot_positions:
                    state = system.get_state_for_robot(rid)
                    current_states[rid] = state
            
            # í–‰ë™ ì„ íƒ (MAPPO)
            actions = {}
            log_probs = {}
            values = {}
            
            for rid in current_states.keys():
                action, log_prob, value = self.agent.get_action(current_states[rid], training=True)
                actions[rid] = action
                log_probs[rid] = log_prob
                values[rid] = value
            
            # ìŠ¤í… ì‹¤í–‰
            observations, rewards, done, status = system.step(actions)
            
            # ê²½í—˜ ì €ì¥
            step_reward = 0.0
            for rid in current_states.keys():
                if rid in rewards:
                    robot_reward = rewards[rid]
                    
                    # ì‹¤íŒ¨ ì‹œ í° í˜ë„í‹°
                    if done and status == STATUS_FAIL:
                        robot_reward -= 300.0
                    elif done and status == STATUS_WIN:
                        robot_reward += 300.0
                    
                    step_reward += robot_reward
                    
                    # MAPPO ë²„í¼ì— ì €ì¥
                    self.agent.store_transition(
                        current_states[rid],
                        actions[rid],
                        robot_reward,
                        values[rid],
                        log_probs[rid],
                        float(done)
                    )
            
            episode_reward += step_reward
            step_count += 1
            
            if done:
                break
        
        avg_reward = episode_reward / num_robots if num_robots > 0 else 0.0
        final_status = system.get_status()
        
        return avg_reward, step_count, final_status


def main():
    print("\n" + "=" * 70)
    print("ğŸ¤– MAPPO ê¸°ë°˜ Curriculum Learning")
    print("=" * 70)
    print("ì „ëµ:")
    print("  Phase 0: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (í˜‘ë ¥ í•™ìŠµ ê¸°ì´ˆ)")
    print("  Phase 1: ë¡œë´‡ 3ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (í˜‘ë ¥ ì‹¬í™”)")
    print("  Phase 2: ë¡œë´‡ 4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ìµœì¢… í˜‘ë ¥)")
    print("  Phase 3: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 1ê°œ")
    print("  Phase 4: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 3ê°œ")
    print("  Phase 5: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 1ê°œ")
    print("  Phase 6: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 2ê°œ")
    print("=" * 70)
    
    # MAPPO ì—ì´ì „íŠ¸ ìƒì„± (í•œ ë²ˆë§Œ!)
    agent = MAPPOAgent(
        state_dim=13,
        action_dim=4,  # ì „ì§„, ì‹œê³„, ë°˜ì‹œê³„, STAY
        num_agents=4,  # ìµœëŒ€ ë¡œë´‡ ìˆ˜
        learning_rate=3e-4,
        gamma=0.99,
        gae_lambda=0.95,
        clip_epsilon=0.2,
        entropy_coef=0.01,
        value_loss_coef=0.5,
        max_grad_norm=0.5,
        device="cpu"
    )
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = MAPPOCurriculumTrainer(
        agent=agent,
        log_interval=50,
        rollout_steps=2048
    )
    
    # Phase 0: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (í˜‘ë ¥ í•™ìŠµ ê¸°ì´ˆ)
    try:
        phase0_stats, phase0_success = trainer.train_phase(
            phase_name="Phase 0: ë¡œë´‡ 2ê°œ í˜‘ë ¥ ê¸°ì´ˆ",
            num_robots=2,
            obstacles=None,
            num_episodes=10000,
            termination_time=100,
            success_threshold=0.4,
            model_path="outputs/mappo_phase0_2robots.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if phase0_success < 0.15:
        print("\nâŒ Phase 0 ì‹¤íŒ¨! í˜‘ë ¥ í•™ìŠµì´ ì œëŒ€ë¡œ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¬ì¡°ì •í•˜ê±°ë‚˜ ì—í”¼ì†Œë“œ ìˆ˜ë¥¼ ëŠ˜ë ¤ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    # Phase 1: ë¡œë´‡ 3ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (í˜‘ë ¥ ì‹¬í™”)
    try:
        phase1_stats, phase1_success = trainer.train_phase(
            phase_name="Phase 1: ë¡œë´‡ 3ê°œ í˜‘ë ¥ ì‹¬í™”",
            num_robots=3,
            obstacles=None,
            num_episodes=15000,
            termination_time=120,
            success_threshold=0.3,
            model_path="outputs/mappo_phase1_3robots.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if phase1_success < 0.1:
        print("\nâš ï¸ Phase 1 ì„±ê³µë¥  ë‚®ìŒ. ê·¸ë˜ë„ Phase 2ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # Phase 2: ë¡œë´‡ 4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ìµœì¢… í˜‘ë ¥)
    try:
        phase2_stats, phase2_success = trainer.train_phase(
            phase_name="Phase 2: ë¡œë´‡ 4ê°œ ìµœì¢… í˜‘ë ¥",
            num_robots=4,
            obstacles=None,
            num_episodes=25000,
            termination_time=150,
            success_threshold=0.25,
            model_path="outputs/mappo_phase2_4robots.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if phase2_success < 0.08:
        print("\nâš ï¸ Phase 2 ì„±ê³µë¥  ë‚®ìŒ. ê·¸ë˜ë„ Phase 3ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # Phase 3: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 1ê°œ
    try:
        phase3_stats, phase3_success = trainer.train_phase(
            phase_name="Phase 3: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 1ê°œ",
            num_robots=4,
            obstacles=[(2, 2)],  # ëª¨ì„œë¦¬ 1ê°œ
            num_episodes=20000,
            termination_time=150,
            success_threshold=0.2,
            model_path="outputs/mappo_phase3_4robots_obs1.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # Phase 4: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 3ê°œ
    try:
        phase4_stats, phase4_success = trainer.train_phase(
            phase_name="Phase 4: ë¡œë´‡ 4ê°œ + ì •ì  ì¥ì• ë¬¼ 3ê°œ",
            num_robots=4,
            obstacles=[(0, 1), (-1, -1), (1, 0)],
            num_episodes=30000,
            termination_time=150,
            success_threshold=0.15,
            model_path="outputs/mappo_phase4_4robots_obs3.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # Phase 5: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 1ê°œ
    moving_obs_1 = create_moving_obstacles(count=1)
    try:
        phase5_stats, phase5_success = trainer.train_phase(
            phase_name="Phase 5: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 1ê°œ",
            num_robots=4,
            obstacles=None,
            moving_obstacles=moving_obs_1,
            num_episodes=25000,
            termination_time=180,
            success_threshold=0.12,
            model_path="outputs/mappo_phase5_4robots_moving1.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # Phase 6: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 2ê°œ
    moving_obs_2 = create_moving_obstacles(count=2)
    try:
        phase6_stats, phase6_success = trainer.train_phase(
            phase_name="Phase 6: ë¡œë´‡ 4ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 2ê°œ",
            num_robots=4,
            obstacles=None,
            moving_obstacles=moving_obs_2,
            num_episodes=35000,
            termination_time=200,
            success_threshold=0.1,
            model_path="outputs/mappo_phase6_4robots_moving2.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ‰ MAPPO Curriculum Learning ì™„ë£Œ!")
    print("=" * 70)
    print(f"Phase 0 (2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ):           {phase0_success*100:5.1f}%")
    print(f"Phase 1 (3ê°œ, ì¥ì• ë¬¼ ì—†ìŒ):           {phase1_success*100:5.1f}%")
    print(f"Phase 2 (4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ):           {phase2_success*100:5.1f}%")
    print(f"Phase 3 (4ê°œ, ì •ì  1ê°œ):              {phase3_success*100:5.1f}%")
    print(f"Phase 4 (4ê°œ, ì •ì  3ê°œ):              {phase4_success*100:5.1f}%")
    print(f"Phase 5 (4ê°œ, ì›€ì§ì„ 1ê°œ):            {phase5_success*100:5.1f}%")
    print(f"Phase 6 (4ê°œ, ì›€ì§ì„ 2ê°œ):            {phase6_success*100:5.1f}%")
    print("=" * 70)
    print("\nì €ì¥ëœ ëª¨ë¸:")
    print("  outputs/mappo_phase0_2robots.pth")
    print("  outputs/mappo_phase1_3robots.pth")
    print("  outputs/mappo_phase2_4robots.pth")
    print("  outputs/mappo_phase3_4robots_obs1.pth")
    print("  outputs/mappo_phase4_4robots_obs3.pth")
    print("  outputs/mappo_phase5_4robots_moving1.pth")
    print("  outputs/mappo_phase6_4robots_moving2.pth")
    print("\ní‰ê°€ ëª…ë ¹ì–´:")
    print("  python3.11 evaluate.py --model outputs/mappo_phase2_4robots.pth --num-robots 4")
    print("  python3.11 evaluate.py --model outputs/mappo_phase4_4robots_obs3.pth --num-robots 4 --obstacles '(0,1),(-1,-1),(1,0)'")
    print("=" * 70)


if __name__ == "__main__":
    main()


"""
Worm Robot Simulation - Curriculum Learning
ì ì§„ì  ë‚œì´ë„ ì¦ê°€ í•™ìŠµ

í•´ê²°í•˜ëŠ” ë¬¸ì œ:
1. Sparse Reward: ë¡œë´‡ 4ê°œ ë™ì‹œ ì„±ê³µì´ ë„ˆë¬´ ì–´ë ¤ì›€
2. í•´ê²°ì±…: 1ê°œ â†’ 2ê°œ â†’ 4ê°œ ìˆœì„œë¡œ ì ì§„ì  í•™ìŠµ

ê° Phase:
- Phase 1: ë¡œë´‡ 1ê°œ â†’ ê¸°ë³¸ í–‰ë™ í•™ìŠµ (ëª©í‘œ ì°¾ì•„ê°€ê¸°)
- Phase 2: ë¡œë´‡ 2ê°œ â†’ ì¶©ëŒ íšŒí”¼ í•™ìŠµ
- Phase 3: ë¡œë´‡ 4ê°œ â†’ ë©€í‹° ë¡œë´‡ í˜‘ë ¥
"""

import sys
import os
import config

# ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rl.agent import DQNAgent
from rl.trainer import DQNTrainer
from rl.demonstrations import get_all_demonstrations
from rl.demonstrations_extended import get_extended_demonstrations
from system import WormRobotSystem


def create_system_with_num_robots(num_robots, obstacles=None):
    """
    ì§€ì •ëœ ë¡œë´‡ ìˆ˜ë¡œ ì‹œìŠ¤í…œ ìƒì„± í•¨ìˆ˜ë¥¼ ë°˜í™˜
    
    Args:
        num_robots: ë¡œë´‡ ìˆ˜
        obstacles: ì¥ì• ë¬¼ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸ [(x, y), ...] (ì„ íƒ)
    
    Returns:
        í•¨ìˆ˜: create_system_fn
    """
    def create_system_fn(rl_agent=None):
        # WormRobotSystemì— num_robotsì™€ obstacles ì „ë‹¬
        system = WormRobotSystem(
            rl_agent=rl_agent, 
            num_robots=num_robots,
            obstacles=obstacles
        )
        return system
    
    return create_system_fn


def train_phase(
    phase_num,
    num_robots,
    num_episodes,
    prev_model_path=None,
    use_demonstrations=True,
    termination_time=100,
    obstacles=None
):
    """
    ë‹¨ì¼ Phase í•™ìŠµ ì‹¤í–‰
    
    Args:
        phase_num: Phase ë²ˆí˜¸ (1, 1.5, 2, 2.5, 3, ...)
        num_robots: ì´ Phaseì˜ ë¡œë´‡ ìˆ˜
        num_episodes: í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜
        prev_model_path: ì´ì „ Phase ëª¨ë¸ ê²½ë¡œ (íŒŒì¸íŠœë‹ìš©)
        use_demonstrations: Happy Path ì‚¬ìš© ì—¬ë¶€
        termination_time: ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ì‹œê°„
        obstacles: ì¥ì• ë¬¼ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸ [(x, y), ...] (ì„ íƒ)
    
    Returns:
        str: ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
    """
    print("\n" + "=" * 70)
    print(f"ğŸ“š Curriculum Learning - Phase {phase_num}")
    print("=" * 70)
    print(f"ë¡œë´‡ ìˆ˜: {num_robots}ê°œ")
    print(f"ì¥ì• ë¬¼ ìˆ˜: {len(obstacles) if obstacles else 0}ê°œ")
    if obstacles:
        print(f"ì¥ì• ë¬¼ ìœ„ì¹˜: {obstacles}")
    print(f"ì—í”¼ì†Œë“œ: {num_episodes}ê°œ")
    print(f"ì´ì „ ëª¨ë¸: {prev_model_path if prev_model_path else 'ì—†ìŒ (ì²˜ìŒë¶€í„°)'}")
    print(f"Demonstrations: {'ì‚¬ìš©' if use_demonstrations else 'ë¯¸ì‚¬ìš©'}")
    print("=" * 70)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° (Step-by-Step ìµœì í™”)
    STATE_DIM = 13
    ACTION_DIM = 4  # 3 â†’ 4 (STAY ì¶”ê°€)
    
    # DQN ì—ì´ì „íŠ¸ ìƒì„±
    agent = DQNAgent(
        state_dim=STATE_DIM,
        action_dim=ACTION_DIM,
        learning_rate=0.0003,    # Step-by-stepì€ ì—…ë°ì´íŠ¸ê°€ ë§ìœ¼ë¯€ë¡œ ë‚®ì¶¤
        gamma=0.99,
        epsilon_start=1.0,
        epsilon_end=0.01,
        epsilon_decay=0.9995,    # Stepì´ ë§ì•„ì§€ë¯€ë¡œ decay ë¹ ë¥´ê²Œ
        use_target_net=False,
        device="cpu"
    )
    
    # ì´ì „ Phase ëª¨ë¸ ë¡œë“œ (íŒŒì¸íŠœë‹!)
    if prev_model_path and os.path.exists(prev_model_path):
        print(f"\nâœ… ì´ì „ Phase ëª¨ë¸ ë¡œë“œ ì¤‘...")
        agent.load(prev_model_path)
        
        # Epsilon ì¡°ì •: ìƒˆë¡œìš´ ìƒí™© íƒí—˜ í•„ìš”
        if phase_num == 2:
            agent.epsilon = 0.6  # Phase 2: ì ì ˆí•œ íƒí—˜
        elif phase_num == 2.5:
            agent.epsilon = 0.5  # Phase 2.5: ì¤‘ê°„ íƒí—˜
        elif phase_num == 3:
            agent.epsilon = 0.4  # Phase 3: ì œí•œì  íƒí—˜
        else:
            agent.epsilon = 0.7  # Phase 1.5: ë†’ì€ íƒí—˜
        
        print(f"   Epsilon ì¡°ì •: {agent.epsilon:.2f} (ìƒˆ ìƒí™© íƒí—˜)")
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = DQNTrainer(
        agent=agent,
        create_system_fn=create_system_with_num_robots(num_robots, obstacles=obstacles),
        num_episodes=num_episodes,
        termination_time=termination_time,
        batch_size=64,            # Step-by-stepì€ ê²½í—˜ì´ ë§ìœ¼ë¯€ë¡œ batch size ì¦ê°€
        buffer_size=50000,        # Buffer í¬ê¸° ëŒ€í­ ì¦ê°€ (step-by-step)
        log_interval=10,
        save_interval=50,
        model_path=f"outputs/curriculum_phase{phase_num}_{num_robots}robots.pth"
    )
    
    # Happy Path (Demonstrations) ì¶”ê°€ - í™•ì¥ ë²„ì „!
    if use_demonstrations:
        print(f"\nğŸ“– Happy Path (Extended Demonstrations) ì¶”ê°€ ì¤‘...")
        # ë¡œë´‡ ìˆ˜ì— ë”°ë¼ ë” ë§ì€ ë°ëª¨ ìƒì„±
        num_random_demos = {1: 100, 2: 150, 4: 200}.get(num_robots, 100)
        demos = get_extended_demonstrations(num_robots=num_robots, num_random=num_random_demos)
        trainer.replay_buffer.add_demonstrations(demos)
        print(f"   í˜„ì¬ Demo ë¹„ìœ¨: {trainer.replay_buffer.get_demo_ratio()*100:.1f}%")
        print(f"   ì´ {len(demos)}ê°œì˜ ì„±ê³µ ê²½í—˜ ì¶”ê°€!")
    
    # í•™ìŠµ ì‹¤í–‰
    print(f"\nğŸš€ Phase {phase_num} í•™ìŠµ ì‹œì‘!\n")
    try:
        stats = trainer.train()
        
        # ê°„ë‹¨í•œ í‰ê°€
        print(f"\nğŸ“Š Phase {phase_num} í‰ê°€ ì¤‘...")
        eval_stats = trainer.evaluate(num_episodes=10)
        
        print(f"\nâœ… Phase {phase_num} ì™„ë£Œ!")
        print(f"   ìµœì¢… ìŠ¹ë¥ : {eval_stats['win_rate']*100:.1f}%")
        print(f"   í‰ê·  ë³´ìƒ: {eval_stats['avg_reward']:.1f}")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ Phase {phase_num} í•™ìŠµ ì¤‘ë‹¨ë¨!")
        trainer._save_model()
    
    # ëª¨ë¸ ê²½ë¡œ ë°˜í™˜
    return trainer.model_path


def main():
    """ë©”ì¸ í•¨ìˆ˜: Curriculum Learning ì‹¤í–‰"""
    print("\n" + "=" * 70)
    print("ğŸ“ Curriculum Learning - Worm Robot í˜‘ë ¥ í•™ìŠµ")
    print("=" * 70)
    print("\nì „ëµ:")
    print("  Phase 1 (ì‰¬ì›€):    ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ì—†ìŒ â†’ ê¸°ë³¸ í–‰ë™ í•™ìŠµ")
    print("  Phase 1.5 (ì‰¬ì›€+): ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ 2-3ê°œ â†’ ì¥ì• ë¬¼ íšŒí”¼ í•™ìŠµ")
    print("  Phase 2 (ì¤‘ê°„):    ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ â†’ ë¡œë´‡ ê°„ í˜‘ë ¥")
    print("  Phase 2.5 (ì¤‘ê°„+): ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ 2-3ê°œ â†’ ë³µí•© íšŒí”¼")
    print("  Phase 3 (ì–´ë ¤ì›€):  ë¡œë´‡ 4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ â†’ ë©€í‹° ë¡œë´‡ í˜‘ë ¥")
    print("\nê° PhaseëŠ” ì´ì „ Phaseì˜ í•™ìŠµëœ ëª¨ë¸ì„ ì´ì–´ë°›ì•„ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤.")
    print("=" * 70)
    
    # outputs ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("outputs", exist_ok=True)
    
    # Phase 1: ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ê¸°ë³¸ í•™ìŠµ)
    phase1_model = train_phase(
        phase_num=1,
        num_robots=1,
        num_episodes=3000,      # Step-by-step: ê²½í—˜ ìˆ˜ì§‘ì´ ë§ì•„ì„œ ì—í”¼ì†Œë“œ ì¤„ì„
        prev_model_path=None,   # ì²˜ìŒë¶€í„°
        use_demonstrations=True,
        termination_time=100,   # ìŠ¤í… ìˆ˜ (ì ë‹¹í•˜ê²Œ ì„¤ì •)
        obstacles=None          # ì¥ì• ë¬¼ ì—†ìŒ
    )
    
    # Phase 1.5: ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ìˆìŒ (ì¥ì• ë¬¼ íšŒí”¼ í•™ìŠµ)
    obstacles_phase15 = [(0, 1), (-1, -1), (1, 0)]  # ì¥ì• ë¬¼ 3ê°œ
    phase15_model = train_phase(
        phase_num=1.5,
        num_robots=1,
        num_episodes=4000,      # ì¥ì• ë¬¼ íšŒí”¼ ì—°ìŠµ
        prev_model_path=phase1_model,  # â¬…ï¸ Phase 1 ëª¨ë¸ íŒŒì¸íŠœë‹!
        use_demonstrations=True,
        termination_time=100,
        obstacles=obstacles_phase15
    )
    
    # Phase 2: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ë¡œë´‡ ê°„ í˜‘ë ¥)
    phase2_model = train_phase(
        phase_num=2,
        num_robots=2,
        num_episodes=5000,      # 2ê°œ ë¡œë´‡ í˜‘ë ¥
        prev_model_path=phase15_model,  # â¬…ï¸ Phase 1.5 ëª¨ë¸ íŒŒì¸íŠœë‹!
        use_demonstrations=True,
        termination_time=120,
        obstacles=None
    )
    
    # Phase 2.5: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ìˆìŒ (ë³µí•© íšŒí”¼)
    obstacles_phase25 = [(0, 2), (-2, 0), (1, -1)]  # ì¥ì• ë¬¼ 3ê°œ
    phase25_model = train_phase(
        phase_num=2.5,
        num_robots=2,
        num_episodes=6000,      # ë³µí•© íšŒí”¼ ì—°ìŠµ
        prev_model_path=phase2_model,  # â¬…ï¸ Phase 2 ëª¨ë¸ íŒŒì¸íŠœë‹!
        use_demonstrations=True,
        termination_time=120,
        obstacles=obstacles_phase25
    )
    
    # Phase 3: ë¡œë´‡ 4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ìµœì¢… ëª©í‘œ)
    phase3_model = train_phase(
        phase_num=3,
        num_robots=4,
        num_episodes=10000,     # ë©€í‹° ë¡œë´‡ í˜‘ë ¥
        prev_model_path=phase25_model,  # â¬…ï¸ Phase 2.5 ëª¨ë¸ íŒŒì¸íŠœë‹!
        use_demonstrations=True,
        termination_time=150    # 4ê°œ ë¡œë´‡ì€ ì‹œê°„ ë” í•„ìš”
    )
    
    # ì™„ë£Œ
    print("\n" + "=" * 70)
    print("ğŸ‰ Curriculum Learning ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nì €ì¥ëœ ëª¨ë¸:")
    print(f"  Phase 1   (1 robot, ì¥ì• ë¬¼ ì—†ìŒ):  {phase1_model}")
    print(f"  Phase 1.5 (1 robot, ì¥ì• ë¬¼ 3ê°œ):  {phase15_model}")
    print(f"  Phase 2   (2 robots, ì¥ì• ë¬¼ ì—†ìŒ): {phase2_model}")
    print(f"  Phase 2.5 (2 robots, ì¥ì• ë¬¼ 3ê°œ): {phase25_model}")
    print(f"  Phase 3   (4 robots, ì¥ì• ë¬¼ ì—†ìŒ): {phase3_model}")
    print("\nìµœì¢… ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
    print(f"  python3.11 evaluate.py --model {phase3_model}")
    print("=" * 70)


if __name__ == "__main__":
    main()


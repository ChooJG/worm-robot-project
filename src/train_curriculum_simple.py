"""
ì´ˆê°„ë‹¨ Curriculum Learning
ë¡œë´‡ 1ê°œ ê¸°ì¤€ìœ¼ë¡œ ë‚œì´ë„ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€

Phase 0: ì¥ì• ë¬¼ ì—†ìŒ (ê¸°ë³¸ ì´ë™)
Phase 1: ì¥ì• ë¬¼ 1ê°œ (ëª¨ì„œë¦¬)
Phase 2: ì¥ì• ë¬¼ 1ê°œ (ì¤‘ì•™ ê·¼ì²˜)
Phase 3: ì¥ì• ë¬¼ 3ê°œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rl.agent import DQNAgent
from rl.replay_buffer import PrioritizedReplayBuffer
from rl.demonstrations_extended import get_extended_demonstrations
from system import WormRobotSystem
from moving_obstacle import create_horizontal_obstacle
from config import STATUS_WIN, STATUS_FAIL, STATUS_RUNNING
import numpy as np

class SimpleCurriculumTrainer:
    """ë‹¨ìˆœí™”ëœ Curriculum Learning íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, agent, batch_size=128, log_interval=100):
        self.agent = agent
        self.batch_size = batch_size
        self.log_interval = log_interval
        self.replay_buffer = PrioritizedReplayBuffer(capacity=100000)
    
    def train_phase(self, phase_name, obstacles, num_episodes, termination_time=80, 
                    success_threshold=0.3, model_path=None, num_robots=1, moving_obstacles=None):
        """
        ë‹¨ì¼ Phase í•™ìŠµ
        
        Args:
            phase_name: Phase ì´ë¦„ (ì˜ˆ: "Phase 0")
            obstacles: ì •ì  ì¥ì• ë¬¼ ë¦¬ìŠ¤íŠ¸ (None or [(x, y), ...])
            num_episodes: í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜
            termination_time: ìµœëŒ€ ìŠ¤í…
            success_threshold: ëª©í‘œ ì„±ê³µë¥  (ì¡°ê¸° ì¢…ë£Œìš©)
            model_path: ì €ì¥í•  ëª¨ë¸ ê²½ë¡œ
            num_robots: ë¡œë´‡ ìˆ˜ (ê¸°ë³¸ê°’ 1)
            moving_obstacles: ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ ë¦¬ìŠ¤íŠ¸ (None or [MovingObstacle, ...])
        """
        print("\n" + "=" * 70)
        print(f"ğŸ“š {phase_name} í•™ìŠµ ì‹œì‘")
        print("=" * 70)
        print(f"ë¡œë´‡ ìˆ˜: {num_robots}ê°œ")
        print(f"ì •ì  ì¥ì• ë¬¼: {obstacles if obstacles else 'ì—†ìŒ'}")
        print(f"ì›€ì§ì´ëŠ” ì¥ì• ë¬¼: {len(moving_obstacles) if moving_obstacles else 0}ê°œ")
        print(f"ì—í”¼ì†Œë“œ: {num_episodes}")
        print(f"ëª©í‘œ ì„±ê³µë¥ : {success_threshold * 100:.0f}%")
        print("=" * 70)
        
        # ì‹œìŠ¤í…œ ìƒì„± í•¨ìˆ˜
        def create_system_fn(rl_agent=None):
            return WormRobotSystem(
                rl_agent=rl_agent, 
                num_robots=num_robots,
                obstacles=obstacles,
                moving_obstacles=moving_obstacles
            )
        
        # ì¤‘ë‹¨ëœ í•™ìŠµ ì¬ê°œ í™•ì¸
        resumed = False
        if model_path:
            # ì„ì‹œ ëª¨ë¸ ê²½ë¡œ í™•ì¸ (ìš°ì„ ìˆœìœ„: interrupted > error)
            tmp_interrupted = model_path.replace('.pth', '_tmp_interrupted.pth')
            tmp_error = model_path.replace('.pth', '_tmp_error.pth')
            
            import os
            if os.path.exists(tmp_interrupted):
                print(f"\nğŸ”„ ì¤‘ë‹¨ëœ í•™ìŠµ ë°œê²¬! ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤...")
                print(f"   ëª¨ë¸ ë¡œë“œ: {tmp_interrupted}")
                self.agent.load(tmp_interrupted)
                resumed = True
                # ë¡œë“œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ (ì„ íƒì )
                # os.remove(tmp_interrupted)
            elif os.path.exists(tmp_error):
                print(f"\nğŸ”„ ì˜¤ë¥˜ë¡œ ì¤‘ë‹¨ëœ í•™ìŠµ ë°œê²¬! ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤...")
                print(f"   ëª¨ë¸ ë¡œë“œ: {tmp_error}")
                self.agent.load(tmp_error)
                resumed = True
                # ë¡œë“œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ (ì„ íƒì )
                # os.remove(tmp_error)
        
        if resumed:
            print(f"   âœ… ì´ì „ í•™ìŠµ ìƒíƒœì—ì„œ ì¬ê°œí•©ë‹ˆë‹¤!")
            print(f"   í˜„ì¬ Epsilon: {self.agent.epsilon:.3f}")
        
        # í†µê³„
        stats = {
            "episode_rewards": [],
            "episode_steps": [],
            "episode_losses": [],
            "success_count": 0,
            "fail_count": 0
        }
        
        # Happy Path ì¶”ê°€
        print(f"\nğŸ“– Happy Path ì¶”ê°€ ì¤‘...")
        
        # ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ì´ ìˆìœ¼ë©´ Happy Path ì‚¬ìš© ì•ˆ í•¨ (ì‹œí–‰ì°©ì˜¤ë¡œ í•™ìŠµ)
        if moving_obstacles and len(moving_obstacles) > 0:
            print(f"   âš ï¸ ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ í™˜ê²½: Happy Path ìƒëµ (ì‹œí–‰ì°©ì˜¤ í•™ìŠµ)")
            demos = []
        elif num_robots == 1:
            if obstacles is None or len(obstacles) == 0:
                # Phase 0: ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ì—†ìŒ - ëŒ€ëŸ‰ì˜ ë°ëª¨
                demos = get_extended_demonstrations(num_robots=1, num_random=3000)
            else:
                # Phase 1-3: ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ìˆìŒ - ì ì€ ë°ëª¨
                demos = get_extended_demonstrations(num_robots=1, num_random=500)
        else:
            # Phase 3.5, 4: ë¡œë´‡ 2ê°œ - ì¶©ë¶„í•œ ë°ëª¨ (ì¤‘ìš”!)
            if obstacles is None or len(obstacles) == 0:
                # ì¥ì• ë¬¼ ì—†ìŒ: ëŒ€ëŸ‰ ë°ëª¨
                demos = get_extended_demonstrations(num_robots=2, num_random=2000)
            else:
                # ì¥ì• ë¬¼ ìˆìŒ: ì¤‘ê°„ ë°ëª¨
                demos = get_extended_demonstrations(num_robots=2, num_random=1000)
        
        if demos:
            self.replay_buffer.add_demonstrations(demos)
            print(f"   âœ… ì´ {len(demos)}ê°œì˜ ì„±ê³µ ê²½í—˜ ì¶”ê°€!")
        else:
            print(f"   â„¹ï¸ Happy Path ì—†ì´ í•™ìŠµ ì‹œì‘")
        
        print(f"\nğŸš€ í•™ìŠµ ì‹œì‘!\n")
        
        best_success_rate = 0.0
        
        # í•™ìŠµ ë£¨í”„
        try:
            for episode in range(num_episodes):
                episode_reward, episode_steps, status = self._run_episode(create_system_fn, termination_time)
                
                # í†µê³„ ê¸°ë¡
                stats["episode_rewards"].append(episode_reward)
                stats["episode_steps"].append(episode_steps)
                
                if status == STATUS_WIN:
                    stats["success_count"] += 1
                elif status == STATUS_FAIL:
                    stats["fail_count"] += 1
                
                # í•™ìŠµ
                if len(self.replay_buffer.buffer) >= self.batch_size:
                    states, actions, rewards, next_states, dones = self.replay_buffer.sample(self.batch_size)
                    batch = list(zip(states, actions, rewards, next_states, dones))
                    loss = self.agent.train(batch)
                    stats["episode_losses"].append(loss)
                
                # Epsilon ê°ì†Œ
                self.agent.update_epsilon()
                
                # ë¡œê·¸ ì¶œë ¥
                if (episode + 1) % self.log_interval == 0:
                    recent = min(self.log_interval, len(stats["episode_rewards"]))
                    avg_reward = sum(stats["episode_rewards"][-recent:]) / recent
                    avg_steps = sum(stats["episode_steps"][-recent:]) / recent
                    avg_loss = sum(stats["episode_losses"][-recent:]) / recent if stats["episode_losses"] else 0
                    
                    # ìµœê·¼ ì„±ê³µë¥  ê³„ì‚°
                    recent_episodes = stats["success_count"] + stats["fail_count"]
                    recent_success_rate = stats["success_count"] / recent_episodes if recent_episodes > 0 else 0
                    
                    print(
                        f"Ep {episode + 1:5d}/{num_episodes} | "
                        f"Reward: {avg_reward:7.1f} | "
                        f"Steps: {avg_steps:4.1f} | "
                        f"Loss: {avg_loss:.2f} | "
                        f"Îµ: {self.agent.epsilon:.3f} | "
                        f"Success: {recent_success_rate*100:4.1f}% | "
                        f"Win: {stats['success_count']:4d}"
                    )
                    
                    # ìµœê³  ì„±ê³µë¥  ê°±ì‹ 
                    if recent_success_rate > best_success_rate:
                        best_success_rate = recent_success_rate
                        if model_path:
                            self.agent.save(model_path)
                            print(f"   âœ… ìƒˆ ìµœê³  ì„±ê³µë¥ ! ëª¨ë¸ ì €ì¥: {model_path}")
                
                # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì²´í¬ (ì¶©ë¶„íˆ í•™ìŠµí–ˆìœ¼ë©´)
                if episode > 1000 and episode % 500 == 0:
                    # ì „ì²´ ì„±ê³µë¥ ë¡œ íŒë‹¨
                    total_episodes = stats["success_count"] + stats["fail_count"]
                    current_success_rate = stats["success_count"] / total_episodes if total_episodes > 0 else 0
                    
                    if current_success_rate >= success_threshold:
                        print(f"\nğŸ‰ ëª©í‘œ ë‹¬ì„±! (ì „ì²´ ì„±ê³µë¥ : {current_success_rate*100:.1f}%)")
                        break
        
        except KeyboardInterrupt:
            print(f"\n\nâš ï¸ ì‚¬ìš©ìê°€ í•™ìŠµì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤!")
            if model_path:
                tmp_path = model_path.replace('.pth', '_tmp_interrupted.pth')
                self.agent.save(tmp_path)
                print(f"   ğŸ’¾ ì„ì‹œ ëª¨ë¸ ì €ì¥: {tmp_path}")
                print(f"   í˜„ì¬ê¹Œì§€ ì§„í–‰: {episode + 1}/{num_episodes} ì—í”¼ì†Œë“œ")
            raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìƒìœ„ì—ì„œ ì²˜ë¦¬
        
        except Exception as e:
            print(f"\n\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if model_path:
                tmp_path = model_path.replace('.pth', '_tmp_error.pth')
                self.agent.save(tmp_path)
                print(f"   ğŸ’¾ ì„ì‹œ ëª¨ë¸ ì €ì¥: {tmp_path}")
            raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìƒìœ„ì—ì„œ ì²˜ë¦¬
        
        # ìµœì¢… ì €ì¥
        if model_path:
            self.agent.save(model_path)
        
        # ìµœì¢… í†µê³„
        total_episodes = stats["success_count"] + stats["fail_count"]
        final_success_rate = stats["success_count"] / total_episodes if total_episodes > 0 else 0
        
        print("\n" + "=" * 70)
        print(f"âœ… {phase_name} ì™„ë£Œ!")
        print("=" * 70)
        print(f"ì´ ì„±ê³µ: {stats['success_count']}")
        print(f"ì´ ì‹¤íŒ¨: {stats['fail_count']}")
        print(f"ìµœì¢… ì„±ê³µë¥ : {final_success_rate * 100:.1f}%")
        print(f"ìµœê³  ì„±ê³µë¥ : {best_success_rate * 100:.1f}%")
        print("=" * 70)
        
        return stats, final_success_rate
    
    def _run_episode(self, create_system_fn, termination_time):
        """ì—í”¼ì†Œë“œ ì‹¤í–‰"""
        system = create_system_fn(rl_agent=self.agent)
        num_robots = len(system.robots)
        
        episode_reward = 0.0
        step_count = 0
        
        while not system.is_done() and step_count < termination_time:
            # í˜„ì¬ ìƒíƒœ
            current_states = {}
            for rid in range(num_robots):
                if rid in system.environment.state.robot_positions:
                    state = system.get_state_for_robot(rid)
                    current_states[rid] = state
            
            # í–‰ë™ ì„ íƒ
            actions = {}
            for rid in current_states.keys():
                action = self.agent.get_action(current_states[rid])
                actions[rid] = action
            
            # ìŠ¤í… ì‹¤í–‰
            observations, rewards, done, status = system.step(actions)
            
            # ë‹¤ìŒ ìƒíƒœ
            next_states = {}
            for rid in range(num_robots):
                if rid in system.environment.state.robot_positions:
                    state = system.get_state_for_robot(rid)
                    next_states[rid] = state
            
            # ê²½í—˜ ì €ì¥
            step_reward = 0.0
            for rid in current_states.keys():
                if rid in next_states and rid in rewards:
                    robot_reward = rewards[rid]
                    
                    # ì‹¤íŒ¨ ì‹œ í° í˜ë„í‹°
                    if done and status == STATUS_FAIL:
                        robot_reward -= 300.0
                    elif done and status == STATUS_WIN:
                        robot_reward += 300.0
                    
                    step_reward += robot_reward
                    
                    self.replay_buffer.add(
                        current_states[rid],
                        actions[rid],
                        robot_reward,
                        next_states[rid],
                        float(done)
                    )
            
            episode_reward += step_reward
            step_count += 1
            
            if done:
                break
        
        avg_reward = episode_reward / num_robots if num_robots > 0 else 0.0
        final_status = system.get_status()
        
        return avg_reward, step_count, final_status


def main():
    print("\n" + "=" * 70)
    print("ğŸ“ ê°œì„ ëœ Curriculum Learning (STAY í•™ìŠµ í¬í•¨)")
    print("=" * 70)
    print("ì „ëµ:")
    print("  Phase 0-3:   ë¡œë´‡ 1ê°œ (ì •ì  ì¥ì• ë¬¼ ë‚œì´ë„ ì¦ê°€)")
    print("  Phase 3.25:  ë¡œë´‡ 1ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ (STAY í•™ìŠµ!) âœ¨")
    print("  Phase 3.5:   ë¡œë´‡ 2ê°œ (ì¥ì• ë¬¼ ì—†ìŒ - í˜‘ë ¥ í•™ìŠµ)")
    print("  Phase 4:     ë¡œë´‡ 2ê°œ + ì •ì  ì¥ì• ë¬¼ (ì¢…í•©)")
    print("=" * 70)
    
    # DQN ì—ì´ì „íŠ¸ ìƒì„± (í•œ ë²ˆë§Œ!)
    agent = DQNAgent(
        state_dim=13,
        action_dim=4,  # 3 â†’ 4 (STAY ì¶”ê°€)
        learning_rate=0.0005,
        gamma=0.95,
        epsilon_start=1.0,
        epsilon_end=0.1,
        epsilon_decay=0.9995,
        use_target_net=True,
        device="cpu"
    )
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = SimpleCurriculumTrainer(
        agent=agent,
        batch_size=128,
        log_interval=100
    )
    
    # Phase 0: ì¥ì• ë¬¼ ì—†ìŒ (ê¸°ë³¸ ì´ë™ í•™ìŠµ)
    try:
        phase0_stats, phase0_success = trainer.train_phase(
            phase_name="Phase 0: ì¥ì• ë¬¼ ì—†ìŒ",
            obstacles=None,
            num_episodes=20000,  # 15000 â†’ 20000 ì¦ê°€
            termination_time=80,
            success_threshold=0.3,  # 50% â†’ 30% ë‚®ì¶¤ (í˜„ì‹¤ì )
            model_path="outputs/curriculum_simple_phase0.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if phase0_success < 0.15:  # 20% â†’ 15% ë‚®ì¶¤
        print("\nâŒ Phase 0 ì‹¤íŒ¨! ê¸°ë³¸ ì´ë™ì¡°ì°¨ í•™ìŠµí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("   í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¬ì¡°ì •í•˜ê±°ë‚˜ ì—í”¼ì†Œë“œ ìˆ˜ë¥¼ ëŠ˜ë ¤ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    # Epsilon ì¬ì¡°ì • (ìƒˆë¡œìš´ ìƒí™© íƒí—˜)
    agent.epsilon = 0.5
    print(f"\nğŸ”„ Phase 1ì„ ìœ„í•´ Epsilon ì¬ì„¤ì •: {agent.epsilon}")
    
    # Phase 1: ì¥ì• ë¬¼ 1ê°œ (ëª¨ì„œë¦¬)
    try:
        phase1_stats, phase1_success = trainer.train_phase(
            phase_name="Phase 1: ì¥ì• ë¬¼ 1ê°œ (ëª¨ì„œë¦¬)",
            obstacles=[(2, 2)],  # ëª¨ì„œë¦¬
            num_episodes=12000,  # 10000 â†’ 12000 ì¦ê°€
            termination_time=80,
            success_threshold=0.2,  # 30% â†’ 20% ë‚®ì¶¤
            model_path="outputs/curriculum_simple_phase1.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if phase1_success < 0.08:  # 10% â†’ 8% ë‚®ì¶¤
        print("\nâš ï¸ Phase 1 ì„±ê³µë¥  ë‚®ìŒ. Phase 2ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    # Epsilon ì¬ì¡°ì •
    agent.epsilon = 0.4
    print(f"\nğŸ”„ Phase 2ë¥¼ ìœ„í•´ Epsilon ì¬ì„¤ì •: {agent.epsilon}")
    
    # Phase 2: ì¥ì• ë¬¼ 1ê°œ (ì¤‘ì•™ ê·¼ì²˜)
    try:
        phase2_stats, phase2_success = trainer.train_phase(
            phase_name="Phase 2: ì¥ì• ë¬¼ 1ê°œ (ì¤‘ì•™ ê·¼ì²˜)",
            obstacles=[(0, 1)],  # ì›ë˜ ì–´ë ¤ì› ë˜ ìœ„ì¹˜
            num_episodes=15000,  # 10000 â†’ 15000 ì¦ê°€
            termination_time=80,
            success_threshold=0.15,  # 20% â†’ 15% ë‚®ì¶¤
            model_path="outputs/curriculum_simple_phase2.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # Epsilon ì¬ì¡°ì •
    agent.epsilon = 0.3
    print(f"\nğŸ”„ Phase 3ì„ ìœ„í•´ Epsilon ì¬ì„¤ì •: {agent.epsilon}")
    
    # Phase 3: ì¥ì• ë¬¼ 3ê°œ
    try:
        phase3_stats, phase3_success = trainer.train_phase(
            phase_name="Phase 3: ì¥ì• ë¬¼ 3ê°œ",
            obstacles=[(0, 1), (-1, -1), (1, 0)],
            num_episodes=30000,  # 20000 â†’ 30000 ì¦ê°€ (ë” ì¶©ë¶„íˆ í•™ìŠµ)
            termination_time=80,
            success_threshold=0.15,  # 10% â†’ 15% ìƒí–¥ (ì¶©ë¶„íˆ ë‹¬ì„± ê°€ëŠ¥)
            model_path="outputs/curriculum_simple_phase3.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # Epsilon ì¬ì¡°ì •
    agent.epsilon = 0.35
    print(f"\nğŸ”„ Phase 3.25ë¥¼ ìœ„í•´ Epsilon ì¬ì„¤ì •: {agent.epsilon}")
    
    # Phase 3.25: ë¡œë´‡ 1ê°œ + ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ (STAY í•™ìŠµ!)
    moving_obs = create_horizontal_obstacle(y=0, speed=1)  # ì¤‘ì•™ ë¼ì¸ì„ ì™•ë³µ
    try:
        phase325_stats, phase325_success = trainer.train_phase(
            phase_name="Phase 3.25: ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ (STAY í•™ìŠµ!)",
            obstacles=None,  # ì •ì  ì¥ì• ë¬¼ ì—†ìŒ
            moving_obstacles=[moving_obs],  # ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ 1ê°œ
            num_episodes=25000,  # ì¶©ë¶„í•œ í•™ìŠµ
            termination_time=100,  # ì›€ì§ì´ëŠ” ì¥ì• ë¬¼ ëŒ€ì‘ ì‹œê°„ í•„ìš”
            success_threshold=0.15,  # 15% ì´ìƒ
            model_path="outputs/curriculum_simple_phase3.25.pth"
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if phase325_success < 0.08:  # 8% ë¯¸ë§Œì´ë©´
        print("\nâš ï¸ Phase 3.25 ì„±ê³µë¥  ë‚®ìŒ. ê·¸ë˜ë„ Phase 3.5ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        # STAYë¥¼ ë°°ì› ë‹¤ë©´ ê´œì°®ìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
    
    # Epsilon ì¬ì¡°ì •
    agent.epsilon = 0.4
    print(f"\nğŸ”„ Phase 3.5ë¥¼ ìœ„í•´ Epsilon ì¬ì„¤ì •: {agent.epsilon}")
    
    # Phase 3.5: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ë‹¤ì¤‘ ë¡œë´‡ í˜‘ë ¥ ê¸°ì´ˆ)
    try:
        phase35_stats, phase35_success = trainer.train_phase(
            phase_name="Phase 3.5: ë¡œë´‡ 2ê°œ (ì¥ì• ë¬¼ ì—†ìŒ)",
            obstacles=None,  # ì¥ì• ë¬¼ ì—†ìŒ (í˜‘ë ¥ í•™ìŠµì— ì§‘ì¤‘)
            num_episodes=30000,
            termination_time=100,  # ë¡œë´‡ 2ê°œë¼ ì‹œê°„ ë” í•„ìš”
            success_threshold=0.15,  # 15% ì´ìƒ
            model_path="outputs/curriculum_simple_phase3.5.pth",
            num_robots=2  # â† ë¡œë´‡ 2ê°œ!
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if phase35_success < 0.05:  # 5% ë¯¸ë§Œì´ë©´
        print("\nâš ï¸ Phase 3.5 ì„±ê³µë¥  ë‚®ìŒ. Phase 4ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    # Epsilon ì¬ì¡°ì •
    agent.epsilon = 0.3
    print(f"\nğŸ”„ Phase 4ë¥¼ ìœ„í•´ Epsilon ì¬ì„¤ì •: {agent.epsilon}")
    
    # Phase 4: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ 1ê°œ (STAY í•™ìŠµ!)
    try:
        phase4_stats, phase4_success = trainer.train_phase(
            phase_name="Phase 4: ë¡œë´‡ 2ê°œ + ì¥ì• ë¬¼ (STAY í™œìš©)",
            obstacles=[(2, 2)],  # ëª¨ì„œë¦¬ 1ê°œ (ì‰¬ìš´ ìœ„ì¹˜)
            num_episodes=30000,  # 25000 â†’ 30000
            termination_time=120,  # 100 â†’ 120 (ë” ì¶©ë¶„í•œ ì‹œê°„)
            success_threshold=0.1,  # 10% ì´ìƒ
            model_path="outputs/curriculum_simple_phase4.pth",
            num_robots=2  # â† ë¡œë´‡ 2ê°œ!
        )
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ‰ Curriculum Learning ì™„ë£Œ!")
    print("=" * 70)
    print(f"Phase 0   (1ê°œ, ì¥ì• ë¬¼ ì—†ìŒ):   {phase0_success*100:5.1f}%")
    print(f"Phase 1   (1ê°œ, ëª¨ì„œë¦¬ 1ê°œ):    {phase1_success*100:5.1f}%")
    print(f"Phase 2   (1ê°œ, ì¤‘ì•™ 1ê°œ):      {phase2_success*100:5.1f}%")
    print(f"Phase 3   (1ê°œ, ì¥ì• ë¬¼ 3ê°œ):    {phase3_success*100:5.1f}%")
    print(f"Phase 3.5 (2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ):   {phase35_success*100:5.1f}%")
    print(f"Phase 4   (2ê°œ, ëª¨ì„œë¦¬ 1ê°œ):    {phase4_success*100:5.1f}%")
    print("=" * 70)
    print("\nì €ì¥ëœ ëª¨ë¸:")
    print("  outputs/curriculum_simple_phase0.pth")
    print("  outputs/curriculum_simple_phase1.pth")
    print("  outputs/curriculum_simple_phase2.pth")
    print("  outputs/curriculum_simple_phase3.pth")
    print("  outputs/curriculum_simple_phase3.5.pth  â† ë¡œë´‡ 2ê°œ (ì¥ì• ë¬¼ ì—†ìŒ)")
    print("  outputs/curriculum_simple_phase4.pth    â† ë¡œë´‡ 2ê°œ + ì¥ì• ë¬¼!")
    print("\ní‰ê°€ ëª…ë ¹ì–´:")
    print("  python3.11 evaluate.py --model outputs/curriculum_simple_phase3.5.pth --num-robots 2")
    print("  python3.11 evaluate.py --model outputs/curriculum_simple_phase4.pth --num-robots 2 --obstacles '(2,2)'")
    print("=" * 70)

if __name__ == "__main__":
    main()


# ğŸ“ Curriculum Learning + Happy Path ê°€ì´ë“œ

## ğŸ“Œ í•´ê²°í•˜ëŠ” ë¬¸ì œ

### ê¸°ì¡´ ë¬¸ì œ: Sparse Reward

```
ë¡œë´‡ 4ê°œê°€ ëª¨ë‘ ì •í™•í•œ ìœ„ì¹˜ì— ë„ë‹¬í•´ì•¼ ì„±ê³µ
  â†“
ëœë¤ íƒí—˜ìœ¼ë¡œëŠ” ì„±ê³µ í™•ë¥  ê±°ì˜ 0%
  â†“
ë³´ìƒì„ ë°›ì€ ê²½í—˜ì´ ì „í˜€ ì—†ìŒ
  â†“
Q-networkê°€ "ì–´ë””ë¡œ ê°€ì•¼ í•˜ëŠ”ì§€" í•™ìŠµ ë¶ˆê°€
  â†“
í•™ìŠµ ì§„í–‰ ì•ˆë¨ âŒ
```

### í•´ê²°ì±… 1: Curriculum Learning (ë‚œì´ë„ ì ì§„ì  ì¦ê°€)

```
Phase 1: ë¡œë´‡ 1ê°œ
  â†’ ì„±ê³µ í™•ë¥  20% (ë†’ìŒ!)
  â†’ "ì „ì§„í•˜ë©´ ëª©í‘œì— ê°€ê¹Œì›Œì§„ë‹¤" í•™ìŠµ
  â†’ ëª¨ë¸ ì €ì¥

Phase 2: ë¡œë´‡ 2ê°œ + Phase 1 ëª¨ë¸ ë¡œë“œ
  â†’ ì´ë¯¸ "ëª©í‘œ ì°¾ì•„ê°€ëŠ” ë²•" ì•Œê³  ìˆìŒ âœ…
  â†’ ì¶”ê°€ë¡œ "ì¶©ëŒ íšŒí”¼" í•™ìŠµ
  â†’ ëª¨ë¸ ì €ì¥

Phase 3: ë¡œë´‡ 4ê°œ + Phase 2 ëª¨ë¸ ë¡œë“œ
  â†’ ê¸°ë³¸ í–‰ë™ + ì¶©ëŒ íšŒí”¼ ì´ë¯¸ ìŠµë“ âœ…
  â†’ "ì—¬ëŸ¬ ë¡œë´‡ ë™ì‹œ ì œì–´" í•™ìŠµ
  â†’ ìµœì¢… ëª¨ë¸ ì™„ì„±!
```

### í•´ê²°ì±… 2: Happy Path (ì„±ê³µ ê²½ë¡œ ì‚¬ì „ ì œê³µ)

```
ë¯¸ë¦¬ ì •ì˜ëœ ì„±ê³µ ê²½ë¡œë¥¼ Replay Bufferì— ì¶”ê°€
  â†“
í•™ìŠµ ì²« ë°°ì¹˜ë¶€í„° "ì„±ê³µ ê²½í—˜" í¬í•¨
  â†“
Q-networkê°€ "ì–´ë–»ê²Œ í•˜ë©´ ì„±ê³µí•˜ëŠ”ì§€" ì¦‰ì‹œ í•™ìŠµ
  â†“
ë¹ ë¥¸ í•™ìŠµ ì‹œì‘ âœ…
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 1. Curriculum Learning í•™ìŠµ ì‹¤í–‰

```bash
cd src
python3.11 train_curriculum.py
```

**ì˜ˆìƒ ì‹œê°„**: 
- Phase 1 (1 ë¡œë´‡): ~30ë¶„
- Phase 2 (2 ë¡œë´‡): ~1ì‹œê°„
- Phase 3 (4 ë¡œë´‡): ~2-3ì‹œê°„
- **ì´ ì•½ 4-5ì‹œê°„**

**í•™ìŠµ ê³¼ì •**:
```
============================================================
ğŸ“š Curriculum Learning - Phase 1
============================================================
ë¡œë´‡ ìˆ˜: 1ê°œ
ì—í”¼ì†Œë“œ: 5000ê°œ
ì´ì „ ëª¨ë¸: ì—†ìŒ (ì²˜ìŒë¶€í„°)
Demonstrations: ì‚¬ìš©
============================================================

âœ… ì´ì „ Phase ëª¨ë¸ ë¡œë“œ ì¤‘...
   Epsilon ì¡°ì •: 0.70 (ìƒˆ ìƒí™© íƒí—˜)

ğŸ“– Happy Path (Demonstrations) ì¶”ê°€ ì¤‘...
âœ… 6ê°œì˜ demonstrationì„ Replay Bufferì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.
   í˜„ì¬ Demo ë¹„ìœ¨: 100.0%

ğŸš€ Phase 1 í•™ìŠµ ì‹œì‘!

Ep   10/5000 | Reward:  -12.5 | Steps:  8.2 | Win:   0 | Fail:   8
Ep   20/5000 | Reward:   15.3 | Steps: 11.4 | Win:   1 | Fail:  16  â¬…ï¸ ì²« ì„±ê³µ!
Ep   50/5000 | Reward:   42.1 | Steps: 14.8 | Win:   8 | Fail:  38
...
Ep 5000/5000 | Reward:  156.7 | Steps: 18.3 | Win: 982 | Fail: 3956

ğŸ“Š Phase 1 í‰ê°€ ì¤‘...
âœ… Phase 1 ì™„ë£Œ!
   ìµœì¢… ìŠ¹ë¥ : 19.6%  â¬…ï¸ ì„±ê³µ!
   í‰ê·  ë³´ìƒ: 152.3
```

### 2. íŠ¹ì • Phaseë§Œ í•™ìŠµ (ìˆ˜ë™ ì œì–´)

Phaseë³„ë¡œ ê°œë³„ í•™ìŠµí•˜ê³  ì‹¶ë‹¤ë©´:

```python
# train_curriculum.py ìˆ˜ì •
def main():
    # Phase 2ë¶€í„° ì‹œì‘ (Phase 1ì€ ì´ë¯¸ ì™„ë£Œ)
    phase2_model = train_phase(
        phase_num=2,
        num_robots=2,
        num_episodes=15000,  # ë” ë§ì´ í•™ìŠµ
        prev_model_path="outputs/curriculum_phase1_1robots.pth",  # Phase 1 ë¡œë“œ
        use_demonstrations=True
    )
```

### 3. í•™ìŠµëœ ëª¨ë¸ í‰ê°€

```bash
cd src

# Phase 3 (ìµœì¢… ëª¨ë¸) í‰ê°€
python3.11 evaluate.py --model outputs/curriculum_phase3_4robots.pth --episodes 50

# Phase 1 í‰ê°€
python3.11 evaluate.py --model outputs/curriculum_phase1_1robots.pth --episodes 20

# ìƒì„¸ ì¶œë ¥
python3.11 evaluate.py --model outputs/curriculum_phase3_4robots.pth --verbose
```

---

## ğŸ“Š ì‘ë™ ì›ë¦¬ ìƒì„¸ ì„¤ëª…

### Curriculum Learningì˜ í•µì‹¬

#### 1. ì ì§„ì  ë‚œì´ë„ ì¦ê°€

```
ë‚œì´ë„     ì„±ê³µ í™•ë¥     í•™ìŠµ íš¨ê³¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1 ë¡œë´‡      20%        â­â­â­â­â­ (ë§¤ìš° ì¢‹ìŒ)
2 ë¡œë´‡       5%        â­â­â­â­ (ì¢‹ìŒ)
4 ë¡œë´‡       1%        â­â­â­ (ì ì ˆ)

vs.

ì²˜ìŒë¶€í„° 4 ë¡œë´‡: 0.001%  âŒ (í•™ìŠµ ë¶ˆê°€)
```

#### 2. íŒŒì¸íŠœë‹ (Fine-tuning)

```python
# Phase 1: ì²˜ìŒë¶€í„° í•™ìŠµ
Q("ëª©í‘œ ì•", "ì „ì§„") = +50  # í•™ìŠµë¨
Q("ëª©í‘œ ì•", "íšŒì „") = -10  # í•™ìŠµë¨

# Phase 2: Phase 1 ëª¨ë¸ ë¡œë“œ
agent.load("phase1.pth")  # â¬…ï¸ ìœ„ Qê°’ë“¤ ìœ ì§€!

# Phase 2ì—ì„œ ì¶”ê°€ í•™ìŠµ
Q("ëª©í‘œ ì• + ë¡œë´‡ ê°ì§€", "íšŒì „") = +30  # ìƒˆë¡œ í•™ìŠµ (ì¶©ëŒ íšŒí”¼)
Q("ëª©í‘œ ì• + ë¡œë´‡ ì—†ìŒ", "ì „ì§„") = +55  # ê¸°ì¡´ +50ì—ì„œ ë¯¸ì„¸ ì¡°ì •
```

**í•µì‹¬**: ì´ì „ ì§€ì‹ì„ ë²„ë¦¬ì§€ ì•Šê³ , ìƒˆë¡œìš´ ì§€ì‹ì„ ì¶”ê°€!

#### 3. Epsilon ì¡°ì •

```python
# Phase 1 ì‹œì‘
agent.epsilon = 1.0  # ëª¨ë“  ê²ƒ íƒí—˜

# Phase 1 ì¢…ë£Œ
agent.epsilon = 0.05  # ê±°ì˜ í™œìš©

# Phase 2 ì‹œì‘ (ëª¨ë¸ ë¡œë“œ í›„)
agent.epsilon = 0.7  # ë‹¤ì‹œ íƒí—˜! (ìƒˆ ìƒí™©: ë¡œë´‡ 2ê°œ)
```

**ì´ìœ **: ìƒˆë¡œìš´ ìƒí™©(ë¡œë´‡ ìˆ˜ ì¦ê°€)ì—ì„œëŠ” ë‹¤ì‹œ íƒí—˜ì´ í•„ìš”!

---

### Happy Path (Demonstrations)ì˜ í•µì‹¬

#### 1. ì„±ê³µ ê²½í—˜ ì‚¬ì „ ì œê³µ

```python
# ë¯¸ë¦¬ ì •ì˜ëœ ì„±ê³µ ê²½ë¡œ
demo = [
    (state=ì´ˆê¸°, action=ì „ì§„, reward=+10, next_state=í•œì¹¸ì•),
    (state=í•œì¹¸ì•, action=ì „ì§„, reward=+20, next_state=ë‘ì¹¸ì•),
    ...
    (state=ê±°ì˜ë„ì°©, action=ì „ì§„, reward=+300, next_state=ì„±ê³µ!) # â­
]

# Replay Bufferì— ì¶”ê°€
replay_buffer.add_demonstrations(demo)

# ì²« í•™ìŠµ ë°°ì¹˜
batch = replay_buffer.sample(32)
# â†’ ì´ ì¤‘ ì¼ë¶€ëŠ” demo ê²½í—˜ (ì„±ê³µ ê²½í—˜!)
# â†’ Q-networkê°€ ì¦‰ì‹œ "ì„±ê³µ ë°©í–¥" í•™ìŠµ ì‹œì‘ âœ…
```

#### 2. í•™ìŠµ ê°€ì†

```
ì¼ë°˜ í•™ìŠµ:
  Episode 1-1000: ì„±ê³µ 0íšŒ â†’ ë°©í–¥ ëª¨ë¦„
  Episode 1001-5000: ì²« ì„±ê³µ â†’ í•™ìŠµ ì‹œì‘

Happy Path ì‚¬ìš©:
  Episode 1: ë°°ì¹˜ì— demo í¬í•¨ â†’ ë°©í–¥ í•™ìŠµ ì‹œì‘ âœ…
  Episode 50: ì´ë¯¸ ëª©í‘œ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì„
  Episode 200: ì²« ì‹¤ì œ ì„±ê³µ! ğŸ‰
  Episode 1000: ì•ˆì •ì  í•™ìŠµ
```

**íš¨ê³¼**: í•™ìŠµ ì‹œê°„ **5-10ë°° ë‹¨ì¶•!**

---

## ğŸ¯ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •

### Phaseë³„ ì—í”¼ì†Œë“œ ìˆ˜

```python
# train_curriculum.py

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (1-2ì‹œê°„)
phase1_episodes = 2000
phase2_episodes = 5000
phase3_episodes = 10000

# ê¶Œì¥ (4-5ì‹œê°„)
phase1_episodes = 5000
phase2_episodes = 10000
phase3_episodes = 20000

# ì² ì €í•œ í•™ìŠµ (8-10ì‹œê°„)
phase1_episodes = 10000
phase2_episodes = 20000
phase3_episodes = 50000
```

### Epsilon ì¡°ì •

```python
# train_phase() í•¨ìˆ˜ ë‚´

# ë” ë§ì€ íƒí—˜ (í•™ìŠµ ëŠë¦¬ì§€ë§Œ ì•ˆì •ì )
if phase_num == 2:
    agent.epsilon = 0.9  # ê¸°ë³¸ 0.7
elif phase_num == 3:
    agent.epsilon = 0.8  # ê¸°ë³¸ 0.5

# ë” ì ì€ íƒí—˜ (í•™ìŠµ ë¹ ë¥´ì§€ë§Œ ë¶ˆì•ˆì •)
if phase_num == 2:
    agent.epsilon = 0.5
elif phase_num == 3:
    agent.epsilon = 0.3
```

### Demonstration ë¹„í™œì„±í™”

```python
# Happy Path ì—†ì´ ìˆœìˆ˜ Curriculum Learningë§Œ
phase1_model = train_phase(
    phase_num=1,
    num_robots=1,
    num_episodes=10000,  # ë” ë§ì€ ì—í”¼ì†Œë“œ í•„ìš”
    use_demonstrations=False  # â¬…ï¸ False
)
```

---

## ğŸ“ˆ í•™ìŠµ ì„±ê³µ ì§€í‘œ

### Phase 1 (ë¡œë´‡ 1ê°œ)

- âœ… **ëª©í‘œ**: ìŠ¹ë¥  15% ì´ìƒ
- â­ **ìš°ìˆ˜**: ìŠ¹ë¥  20% ì´ìƒ
- ğŸ¯ **í‰ê·  ë³´ìƒ**: +100 ì´ìƒ

### Phase 2 (ë¡œë´‡ 2ê°œ)

- âœ… **ëª©í‘œ**: ìŠ¹ë¥  3% ì´ìƒ
- â­ **ìš°ìˆ˜**: ìŠ¹ë¥  5% ì´ìƒ
- ğŸ¯ **í‰ê·  ë³´ìƒ**: +50 ì´ìƒ

### Phase 3 (ë¡œë´‡ 4ê°œ)

- âœ… **ëª©í‘œ**: ìŠ¹ë¥  0.5% ì´ìƒ (100ë²ˆ ì¤‘ 1ë²ˆ)
- â­ **ìš°ìˆ˜**: ìŠ¹ë¥  1% ì´ìƒ
- ğŸ¯ **í‰ê·  ë³´ìƒ**: +20 ì´ìƒ

---

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Phase 1ì—ì„œ í•™ìŠµì´ ì•ˆë¨

```bash
# 1. Demonstrationì´ ì œëŒ€ë¡œ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
# train_curriculum.py ë¡œê·¸ì—ì„œ í™•ì¸:
âœ… 6ê°œì˜ demonstrationì„ Replay Bufferì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.
   í˜„ì¬ Demo ë¹„ìœ¨: 100.0%

# 2. ë³´ìƒ í•¨ìˆ˜ í™•ì¸
# environment.pyì˜ _calculate_rewards() í™•ì¸

# 3. ì—í”¼ì†Œë“œ ìˆ˜ ì¦ê°€
phase1_episodes = 10000  # ê¸°ë³¸ 5000ì—ì„œ ì¦ê°€
```

### Phase 2/3ì—ì„œ Phase 1 ì§€ì‹ì„ ìƒì–´ë²„ë¦¼

```python
# Epsilonì„ ë„ˆë¬´ ë†’ê²Œ ì„¤ì •í•˜ë©´ ê¸°ì¡´ ì§€ì‹ ë§ê°
# í•´ê²°: Epsilon ë‚®ì¶”ê¸°
if phase_num == 2:
    agent.epsilon = 0.5  # 0.7 â†’ 0.5
elif phase_num == 3:
    agent.epsilon = 0.3  # 0.5 â†’ 0.3
```

### í•™ìŠµ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼

```python
# 1. termination_time ì¤„ì´ê¸°
termination_time=60  # ê¸°ë³¸ 100ì—ì„œ ê°ì†Œ

# 2. ì—í”¼ì†Œë“œ ìˆ˜ ì¤„ì´ê¸° (í…ŒìŠ¤íŠ¸ìš©)
num_episodes=1000  # ëŒ€ì‹  ì„±ëŠ¥ì€ ë‚®ì•„ì§

# 3. ë¡œë´‡ ìˆ˜ ì¶•ì†Œ
# Phase 3ë¥¼ ë¡œë´‡ 3ê°œë¡œ ë³€ê²½
phase3_model = train_phase(
    phase_num=3,
    num_robots=3,  # 4 â†’ 3
    ...
)
```

---

## ğŸ“š ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´

### 1. Adaptive Curriculum

í˜„ì¬ ì„±ëŠ¥ì— ë”°ë¼ ìë™ìœ¼ë¡œ ë‹¤ìŒ Phaseë¡œ ì´ë™:

```python
# Phase 1ì—ì„œ ìŠ¹ë¥  20% ë‹¬ì„± ì‹œ ìë™ìœ¼ë¡œ Phase 2ë¡œ
if current_win_rate > 0.20:
    print("âœ… Phase 1 ëª©í‘œ ë‹¬ì„±! Phase 2ë¡œ ì´ë™...")
    break
```

### 2. ë” ë§ì€ Demonstration

```python
# rl/demonstrations.pyì— ê²½ë¡œ ì¶”ê°€
def create_demonstration_complex_path():
    """ë³µì¡í•œ ê²½ë¡œ ë°ëª¨"""
    # íšŒì „ â†’ ì „ì§„ â†’ íšŒì „ â†’ ì „ì§„
    ...
```

### 3. Multi-Phase í™•ì¥

```python
# Phase 1.5: ë¡œë´‡ 1.5ê°œ? (í•œ ë¡œë´‡ì€ ê³ ì •)
# Phase 2.5: ë¡œë´‡ 3ê°œ
# ë”ìš± ì´˜ì´˜í•œ ë‚œì´ë„ ì¡°ì ˆ
```

---

## ğŸ‰ ìš”ì•½

**Curriculum Learning + Happy Path = ìµœê°• ì¡°í•©!**

| ë°©ë²• | íš¨ê³¼ | êµ¬í˜„ ë‚œì´ë„ |
|------|------|------------|
| Curriculum Learning | â­â­â­â­â­ | ì¤‘ê°„ |
| Happy Path | â­â­â­â­ | ì‰¬ì›€ |
| ë‘˜ ë‹¤ ì‚¬ìš© | â­â­â­â­â­â­ | ì¤‘ê°„ |

**ì‹¤í–‰ ëª…ë ¹**:
```bash
cd src
python3.11 train_curriculum.py
```

**ê²°ê³¼ í™•ì¸**:
```bash
python3.11 evaluate.py --model outputs/curriculum_phase3_4robots.pth
```


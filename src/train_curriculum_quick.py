"""
Worm Robot Simulation - Curriculum Learning (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ë²„ì „)
ì ì§„ì  ë‚œì´ë„ ì¦ê°€ í•™ìŠµ - ì ì€ ì—í”¼ì†Œë“œë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸

âš ï¸ ì£¼ì˜: ì´ ë²„ì „ì€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤. 
ì‹¤ì œ í•™ìŠµì€ train_curriculum.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""

import sys
import os
import config

# ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rl.agent import DQNAgent
from rl.trainer import DQNTrainer
from rl.demonstrations import get_all_demonstrations
from rl.demonstrations_extended import get_extended_demonstrations
from system import WormRobotSystem


def create_system_with_num_robots(num_robots, obstacles=None):
    """
    ì§€ì •ëœ ë¡œë´‡ ìˆ˜ë¡œ ì‹œìŠ¤í…œ ìƒì„± í•¨ìˆ˜ë¥¼ ë°˜í™˜
    
    Args:
        num_robots: ë¡œë´‡ ìˆ˜
        obstacles: ì¥ì• ë¬¼ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸ [(x, y), ...] (ì„ íƒ)
    
    Returns:
        í•¨ìˆ˜: create_system_fn
    """
    def create_system_fn(rl_agent=None):
        # WormRobotSystemì— num_robotsì™€ obstacles ì „ë‹¬
        system = WormRobotSystem(
            rl_agent=rl_agent, 
            num_robots=num_robots,
            obstacles=obstacles
        )
        return system
    
    return create_system_fn


def train_phase(
    phase_num,
    num_robots,
    num_episodes,
    prev_model_path=None,
    use_demonstrations=True,
    termination_time=100,
    obstacles=None
):
    """
    ë‹¨ì¼ Phase í•™ìŠµ ì‹¤í–‰ (ë¹ ë¥¸ ë²„ì „)
    
    Args:
        phase_num: Phase ë²ˆí˜¸ (1, 1.5, 2, 2.5, 3, ...)
        num_robots: ì´ Phaseì˜ ë¡œë´‡ ìˆ˜
        num_episodes: í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜
        prev_model_path: ì´ì „ Phase ëª¨ë¸ ê²½ë¡œ (íŒŒì¸íŠœë‹ìš©)
        use_demonstrations: Happy Path ì‚¬ìš© ì—¬ë¶€
        termination_time: ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ì‹œê°„
        obstacles: ì¥ì• ë¬¼ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸ [(x, y), ...] (ì„ íƒ)
    
    Returns:
        str: ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
    """
    print("\n" + "=" * 70)
    print(f"ğŸ“š Curriculum Learning (Quick Test) - Phase {phase_num}")
    print("=" * 70)
    print(f"ë¡œë´‡ ìˆ˜: {num_robots}ê°œ")
    print(f"ì¥ì• ë¬¼ ìˆ˜: {len(obstacles) if obstacles else 0}ê°œ")
    if obstacles:
        print(f"ì¥ì• ë¬¼ ìœ„ì¹˜: {obstacles}")
    print(f"ì—í”¼ì†Œë“œ: {num_episodes}ê°œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)")
    print(f"ì´ì „ ëª¨ë¸: {prev_model_path if prev_model_path else 'ì—†ìŒ (ì²˜ìŒë¶€í„°)'}")
    print(f"Demonstrations: {'ì‚¬ìš©' if use_demonstrations else 'ë¯¸ì‚¬ìš©'}")
    print("=" * 70)
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    STATE_DIM = 13
    ACTION_DIM = 4  # 3 â†’ 4 (STAY ì¶”ê°€)
    
    # DQN ì—ì´ì „íŠ¸ ìƒì„±
    agent = DQNAgent(
        state_dim=STATE_DIM,
        action_dim=ACTION_DIM,
        learning_rate=0.001,
        gamma=0.99,
        epsilon_start=1.0,
        epsilon_end=0.01,
        epsilon_decay=0.999,     # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: ë” ë¹ ë¥¸ ê°ì†Œ
        use_target_net=False,
        device="cpu"
    )
    
    # ì´ì „ Phase ëª¨ë¸ ë¡œë“œ (íŒŒì¸íŠœë‹!)
    if prev_model_path and os.path.exists(prev_model_path):
        print(f"\nâœ… ì´ì „ Phase ëª¨ë¸ ë¡œë“œ ì¤‘...")
        agent.load(prev_model_path)
        
        # Epsilon ì¡°ì •: ìƒˆë¡œìš´ ìƒí™© íƒí—˜ í•„ìš”
        if phase_num == 2:
            agent.epsilon = 0.7  # Phase 2: ì¤‘ê°„ íƒí—˜
        elif phase_num == 3:
            agent.epsilon = 0.5  # Phase 3: ì ë‹¹í•œ íƒí—˜
        else:
            agent.epsilon = 0.8  # ê¸°íƒ€: ë†’ì€ íƒí—˜
        
        print(f"   Epsilon ì¡°ì •: {agent.epsilon:.2f} (ìƒˆ ìƒí™© íƒí—˜)")
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = DQNTrainer(
        agent=agent,
        create_system_fn=create_system_with_num_robots(num_robots, obstacles=obstacles),
        num_episodes=num_episodes,
        termination_time=termination_time,
        batch_size=32,
        buffer_size=10000,
        log_interval=100,        # 100 ì—í”¼ì†Œë“œë§ˆë‹¤ ë¡œê·¸
        save_interval=500,       # 500 ì—í”¼ì†Œë“œë§ˆë‹¤ ì €ì¥
        model_path=f"outputs/quick_phase{phase_num}_{num_robots}robots.pth",
        use_tensorboard=False    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: TensorBoard ë¹„í™œì„±í™”
    )
    
    # Happy Path (Demonstrations) ì¶”ê°€ - í™•ì¥ ë²„ì „!
    if use_demonstrations:
        print(f"\nğŸ“– Happy Path (Extended Demonstrations) ì¶”ê°€ ì¤‘...")
        # ë¡œë´‡ ìˆ˜ì— ë”°ë¼ ë” ë§ì€ ë°ëª¨ ìƒì„±
        num_random_demos = {1: 50, 2: 80, 4: 100}.get(num_robots, 50)
        demos = get_extended_demonstrations(num_robots=num_robots, num_random=num_random_demos)
        trainer.replay_buffer.add_demonstrations(demos)
        print(f"   í˜„ì¬ Demo ë¹„ìœ¨: {trainer.replay_buffer.get_demo_ratio()*100:.1f}%")
        print(f"   ì´ {len(demos)}ê°œì˜ ì„±ê³µ ê²½í—˜ ì¶”ê°€!")
    
    # í•™ìŠµ ì‹¤í–‰
    print(f"\nğŸš€ Phase {phase_num} í•™ìŠµ ì‹œì‘!\n")
    try:
        stats = trainer.train()
        
        # ê°„ë‹¨í•œ í‰ê°€
        print(f"\nğŸ“Š Phase {phase_num} í‰ê°€ ì¤‘...")
        eval_stats = trainer.evaluate(num_episodes=10)
        
        print(f"\nâœ… Phase {phase_num} ì™„ë£Œ!")
        print(f"   ìµœì¢… ìŠ¹ë¥ : {eval_stats['win_rate']*100:.1f}%")
        print(f"   í‰ê·  ë³´ìƒ: {eval_stats['avg_reward']:.1f}")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ Phase {phase_num} í•™ìŠµ ì¤‘ë‹¨ë¨!")
        trainer._save_model()
    
    # ëª¨ë¸ ê²½ë¡œ ë°˜í™˜
    return trainer.model_path


def main():
    """ë©”ì¸ í•¨ìˆ˜: Curriculum Learning ë¹ ë¥¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("ğŸ“ Curriculum Learning - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ë²„ì „")
    print("=" * 70)
    print("\nâš ï¸ ì£¼ì˜: ì´ ë²„ì „ì€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤.")
    print("   ì‹¤ì œ í•™ìŠµì€ train_curriculum.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    print("\nì „ëµ:")
    print("  Phase 1 (ì‰¬ì›€):    ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ì—†ìŒ â†’ 500 ì—í”¼ì†Œë“œ")
    print("  Phase 1.5 (ì‰¬ì›€+): ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ 2ê°œ â†’ 800 ì—í”¼ì†Œë“œ")
    print("  Phase 2 (ì¤‘ê°„):    ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ â†’ 1,500 ì—í”¼ì†Œë“œ")
    print("  Phase 2.5 (ì¤‘ê°„+): ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ 2ê°œ â†’ 2,000 ì—í”¼ì†Œë“œ")
    print("  Phase 3 (ì–´ë ¤ì›€):  ë¡œë´‡ 4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ â†’ 3,000 ì—í”¼ì†Œë“œ")
    print("\nì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 1~1.5ì‹œê°„")
    print("=" * 70)
    
    # outputs ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("outputs", exist_ok=True)
    
    # Phase 1: ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ê¸°ë³¸ í•™ìŠµ)
    phase1_model = train_phase(
        phase_num=1,
        num_robots=1,
        num_episodes=500,       # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        prev_model_path=None,
        use_demonstrations=True,
        termination_time=80,
        obstacles=None
    )
    
    # Phase 1.5: ë¡œë´‡ 1ê°œ, ì¥ì• ë¬¼ ìˆìŒ (ì¥ì• ë¬¼ íšŒí”¼)
    obstacles_phase15 = [(0, 1), (-1, -1)]  # ì¥ì• ë¬¼ 2ê°œ
    phase15_model = train_phase(
        phase_num=1.5,
        num_robots=1,
        num_episodes=800,       # ì¥ì• ë¬¼ íšŒí”¼ ì—°ìŠµ
        prev_model_path=phase1_model,
        use_demonstrations=True,
        termination_time=80,
        obstacles=obstacles_phase15
    )
    
    # Phase 2: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ë¡œë´‡ ê°„ í˜‘ë ¥)
    phase2_model = train_phase(
        phase_num=2,
        num_robots=2,
        num_episodes=1500,      # 2ê°œ ë¡œë´‡ í˜‘ë ¥
        prev_model_path=phase15_model,
        use_demonstrations=True,
        termination_time=100,
        obstacles=None
    )
    
    # Phase 2.5: ë¡œë´‡ 2ê°œ, ì¥ì• ë¬¼ ìˆìŒ (ë³µí•© íšŒí”¼)
    obstacles_phase25 = [(0, 2), (-2, 0)]  # ì¥ì• ë¬¼ 2ê°œ
    phase25_model = train_phase(
        phase_num=2.5,
        num_robots=2,
        num_episodes=2000,      # ë³µí•© íšŒí”¼ ì—°ìŠµ
        prev_model_path=phase2_model,
        use_demonstrations=True,
        termination_time=100,
        obstacles=obstacles_phase25
    )
    
    # Phase 3: ë¡œë´‡ 4ê°œ, ì¥ì• ë¬¼ ì—†ìŒ (ìµœì¢… ëª©í‘œ)
    phase3_model = train_phase(
        phase_num=3,
        num_robots=4,
        num_episodes=3000,      # ë©€í‹° ë¡œë´‡ í˜‘ë ¥
        prev_model_path=phase25_model,
        use_demonstrations=True,
        termination_time=120,
        obstacles=None
    )
    
    # ì™„ë£Œ
    print("\n" + "=" * 70)
    print("ğŸ‰ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nì €ì¥ëœ ëª¨ë¸:")
    print(f"  Phase 1   (1 robot, ì¥ì• ë¬¼ ì—†ìŒ):  {phase1_model}")
    print(f"  Phase 1.5 (1 robot, ì¥ì• ë¬¼ 2ê°œ):  {phase15_model}")
    print(f"  Phase 2   (2 robots, ì¥ì• ë¬¼ ì—†ìŒ): {phase2_model}")
    print(f"  Phase 2.5 (2 robots, ì¥ì• ë¬¼ 2ê°œ): {phase25_model}")
    print(f"  Phase 3   (4 robots, ì¥ì• ë¬¼ ì—†ìŒ): {phase3_model}")
    print("\nâš ï¸ ì´ ëª¨ë¸ë“¤ì€ í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤. ì„±ëŠ¥ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("\nğŸ’¡ ì‹¤ì œ í•™ìŠµì„ ìœ„í•´:")
    print("   python3.11 train_curriculum.py")
    print("=" * 70)


if __name__ == "__main__":
    main()


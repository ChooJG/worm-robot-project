"""
Worm Robot Simulation - Controller Model
ì»¨íŠ¸ë¡¤ëŸ¬ DEVS ëª¨ë¸ ì •ì˜ (ê°•í™”í•™ìŠµ ì—°ë™ ì§€ì )
"""

import random
from pypdevs.DEVS import AtomicDEVS
from pypdevs.infinity import INFINITY

from config import (
    STATUS_RUNNING,
    ACTION_MOVE,
    ACTION_ROTATE_CW,
    ACTION_ROTATE_CCW,
    ACTION_STAY,
)


# ========================================
# Controller ìƒíƒœ í´ë˜ìŠ¤
# ========================================

class ControllerState:
    """ì»¨íŠ¸ë¡¤ëŸ¬ì˜ ë‚´ë¶€ ìƒíƒœë¥¼ í‘œí˜„í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.observations = {}
        self.status = STATUS_RUNNING
        self.step = 0
        self.phase = "IDLE"  # ìƒíƒœ: IDLE, DECIDING

    def __str__(self):
        return (
            f"Controller["
            f"ìƒíƒœ:{self.phase},"
            f"ìŠ¤í…:{self.step},"
            f"ê²Œì„ìƒíƒœ:{self.status}]"
        )


# ========================================
# Controller ëª¨ë¸ (Atomic DEVS)
# ========================================

class Controller(AtomicDEVS):
    """
    ë¡œë´‡ë“¤ì˜ í–‰ë™ì„ ê²°ì •í•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ DEVS ëª¨ë¸

    ê°•í™”í•™ìŠµ ì—°ë™ ì§€ì :
    - _select_action() ë©”ì„œë“œë¥¼ ìˆ˜ì •í•˜ì—¬ RL ì—ì´ì „íŠ¸ í†µí•© ê°€ëŠ¥
    """

    def __init__(self, num_robots=1, rl_agent=None):
        """
        Args:
            num_robots: ë¡œë´‡ ìˆ˜
            rl_agent: (ì„ íƒ) ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        """
        AtomicDEVS.__init__(self, "Controller")
        self.num_robots = num_robots
        self.state = ControllerState()
        self.rl_agent = rl_agent  # ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ (Noneì´ë©´ íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©)

        # ì…ë ¥ í¬íŠ¸
        self.obs_in = self.addInPort("obs_in")          # ê´€ì°° ë°ì´í„°
        self.status_in = self.addInPort("status_in")    # ê²Œì„ ìƒíƒœ

        # ì¶œë ¥ í¬íŠ¸ (ë¡œë´‡ë“¤ë¡œ)
        self.action_out = [self.addOutPort(f"action{i}_out") for i in range(num_robots)]

    def timeAdvance(self):
        """ì‹œê°„ ì§„í–‰ í•¨ìˆ˜"""
        if self.state.phase == "IDLE":
            return INFINITY  # ê´€ì°° ë°ì´í„° ëŒ€ê¸°
        elif self.state.phase == "DECIDING":
            return 0  # ì¦‰ì‹œ í–‰ë™ ê²°ì •
        return INFINITY

    def intTransition(self):
        """ë‚´ë¶€ ì „ì´ í•¨ìˆ˜ - í–‰ë™ ê²°ì • ì™„ë£Œ"""
        if self.state.phase == "DECIDING":
            self.state.phase = "IDLE"
        return self.state

    def extTransition(self, inputs):
        """ì™¸ë¶€ ì „ì´ í•¨ìˆ˜ - ê´€ì°° ë°ì´í„° ìˆ˜ì‹ """
        # ê´€ì°° ë°ì´í„° ìˆ˜ì‹ 
        obs = inputs.get(self.obs_in)
        if obs:
            self.state.observations = obs

        # ê²Œì„ ìƒíƒœ ìˆ˜ì‹ 
        status = inputs.get(self.status_in)
        if status:
            self.state.status = status["status"]
            self.state.step = status["step"]

        # ê²Œì„ì´ ì§„í–‰ ì¤‘ì´ê³  ê´€ì°° ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê²°ì • ì‹œì‘
        if self.state.observations and self.state.status == STATUS_RUNNING:
            self.state.phase = "DECIDING"

        return self.state

    def outputFnc(self):
        """ì¶œë ¥ í•¨ìˆ˜ - ê° ë¡œë´‡ì— í–‰ë™ ëª…ë ¹ ì „ì†¡"""
        if self.state.phase == "DECIDING":
            actions = {}
            for rid in range(self.num_robots):
                if rid in self.state.observations:
                    action = self._select_action(rid, self.state.observations[rid])
                    actions[self.action_out[rid]] = action
            return actions
        return {}

    def _select_action(self, rid, obs):
        """
        rid: ë¡œë´‡ ID
        obs: í•´ë‹¹ ë¡œë´‡ì˜ ê´€ì¸¡ ë”•ì…”ë„ˆë¦¬
        """
        if self.rl_agent is not None:
            # ============ 1) ì£¼ë³€ ë¡œë´‡ ê±°ë¦¬ ê¸°ë°˜ ìœ„í—˜ ê°ì§€ ============
            own_head = obs["own_head"]              # ë‚´ ì•ë°œ ì¢Œí‘œ (x, y)
            detected = obs["detected_robots"]       # ì„¼ì„œì— ì¡íŒ ë‹¤ë¥¸ ë¡œë´‡ë“¤ ë¦¬ìŠ¤íŠ¸

            danger = False
            for robot in detected:
                # head / tail ë‘˜ ë‹¤ ê²€ì‚¬
                for key in ("head", "tail"):
                    other = robot[key]              # (x, y)
                    dx = abs(other[0] - own_head[0])
                    dy = abs(other[1] - own_head[1])
                    # ìƒ/í•˜/ì¢Œ/ìš°/ëŒ€ê°ì„  1ì¹¸ ì´ë‚´ â†’ max(|dx|, |dy|) <= 1
                    if max(dx, dy) <= 1:
                        danger = True
                        break
                if danger:
                    break

            # ğŸ”’ ì•ˆì „ ë£°: ì£¼ë³€ 1ì¹¸ ì•ˆì— ë‹¤ë¥¸ ë¡œë´‡ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ STAY
            if danger:
                return {"type": ACTION_STAY}

            # ============ 2) ì•ˆì „í•  ë•Œë§Œ RLì—ê²Œ ë§¡ê¹€ ============
            state = self._observation_to_state(obs)
            action_idx = self.rl_agent.get_action(state, training=True)

            # MAPPO ìª½ì´ action_dim=4 ì´ë¯€ë¡œ 4ê°œ ëª¨ë‘ ë§¤í•‘
            action_types = [
                ACTION_MOVE,
                ACTION_ROTATE_CW,
                ACTION_ROTATE_CCW,
                ACTION_STAY,   # 4ë²ˆì§¸ ì•¡ì…˜ì€ ìë°œì  STAY
            ]

            # ë°©ì–´ ì½”ë“œ: ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ STAY
            if not (0 <= action_idx < len(action_types)):
                return {"type": ACTION_STAY}

            return {"type": action_types[action_idx]}


    def _observation_to_state(self, obs):
        """
        ê´€ì°° ë°ì´í„°ë¥¼ RL ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ìƒíƒœ í‘œí˜„ìœ¼ë¡œ ë³€í™˜

        Args:
            obs: ê´€ì°° ë°ì´í„°

        Returns:
            ê°•í™”í•™ìŠµ ìƒíƒœ í‘œí˜„ (numpy array)
        """
        import numpy as np
        
        # ìì‹ ì˜ ìœ„ì¹˜ (ì •ê·œí™”: -3~3 â†’ -1~1)
        own_head = obs["own_head"]
        own_tail = obs["own_tail"]
        
        # ëª©í‘œ ìœ„ì¹˜
        goal_position = obs["goal_position"]
        
        # ëª©í‘œê¹Œì§€ ë²¡í„° ê³„ì‚°
        vector_to_goal_head = (goal_position[0] - own_head[0], goal_position[1] - own_head[1])
        vector_to_goal_tail = (0 - own_tail[0], 0 - own_tail[1])  # ë’·ë°œì€ í•­ìƒ (0,0)
        
        # ë°©í–¥ (0~3)
        direction = obs["own_direction"]
        
        # ì£¼ë³€ ë¡œë´‡ ì •ë³´ (ê°„ë‹¨í•˜ê²Œ: ê°œìˆ˜ì™€ ê°€ì¥ ê°€ê¹Œìš´ ë¡œë´‡ê¹Œì§€ ê±°ë¦¬)
        detected = obs["detected_robots"]
        num_nearby = len(detected)
        
        closest_dist = 10.0  # ê¸°ë³¸ê°’ (ë©€ë¦¬ ìˆìŒ)
        if detected:
            for robot in detected:
                dist = abs(robot["head"][0] - own_head[0]) + abs(robot["head"][1] - own_head[1])
                closest_dist = min(closest_dist, dist)
        
        # ìƒíƒœ ë²¡í„° êµ¬ì„± (13ì°¨ì›)
        state = np.array([
            own_head[0] / 3.0,          # -1 ~ 1
            own_head[1] / 3.0,          # -1 ~ 1
            own_tail[0] / 3.0,          # -1 ~ 1
            own_tail[1] / 3.0,          # -1 ~ 1
            direction / 3.0,            # 0 ~ 1
            vector_to_goal_head[0] / 6.0,  # -1 ~ 1
            vector_to_goal_head[1] / 6.0,  # -1 ~ 1
            vector_to_goal_tail[0] / 6.0,  # -1 ~ 1
            vector_to_goal_tail[1] / 6.0,  # -1 ~ 1
            goal_position[0] / 3.0,     # -1 ~ 1
            goal_position[1] / 3.0,     # -1 ~ 1
            num_nearby / 3.0,           # 0 ~ 1
            closest_dist / 10.0         # 0 ~ 1
        ], dtype=np.float32)
        
        return state
